{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669c1d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atothegodd/living_lab/living_lab/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict, field\n",
    "\n",
    "import dspy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0245b",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 1. DATA LOADING & MODEL CONFIG\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c487f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = dspy.LM(\n",
    "#     model=\"ollama/gemma3:27b\",\n",
    "#     api_base=api_base,\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=2000\n",
    "# )\n",
    "\n",
    "# llm = dspy.LM(\n",
    "#     model=\"ollama/ministral-3:8b\",\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=2000\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Setup complete. Run ID: 2026-01-29_18-43-27\n",
      "âœ“ Students: 8\n"
     ]
    }
   ],
   "source": [
    "students_df = pd.read_csv(\"students.csv\")\n",
    "\n",
    "# Configure LLM (Ollama or OpenAI)\n",
    "\n",
    "LLM_URL = os.getenv(\"LLM_URL_2\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "API_KEY = 'sss'\n",
    "\n",
    "llm = dspy.LM(\n",
    "    model=f'ollama/{MODEL_NAME}',\n",
    "    api_base=LLM_URL, \n",
    "    api_key=API_KEY, \n",
    "    cache=False\n",
    ")\n",
    "\n",
    "\n",
    "dspy.configure(lm=llm, tracà¹…k_usage=False)\n",
    "\n",
    "dspy.settings.configure(lm=llm)\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\") # à¹€à¸”à¸°à¸«à¸²à¸¡à¸²à¹ƒà¸«à¹‰à¸„à¸£à¸±à¸Š\n",
    "\n",
    "\n",
    "RUN_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RUN_DIR = f\"logs/run_{RUN_ID}\"\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "\n",
    "MAX_PROJECTS = 5\n",
    "print(f\"âœ“ Setup complete. Run ID: {RUN_ID}\")\n",
    "print(f\"âœ“ Students: {len(students_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae57bc",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 2. CORE DATA STRUCTURES (STATE)\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f9d4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProjectRole:\n",
    "    \"\"\"Represents a single human role in a project.\"\"\"\n",
    "    role: str\n",
    "    quota: int\n",
    "    responsibility: str\n",
    "    required_skills: List[str]\n",
    "\n",
    "    def validate(self) -> bool:\n",
    "        return (\n",
    "            len(self.role.strip()) > 0\n",
    "            and self.quota > 0\n",
    "            and len(self.responsibility.strip()) > 0\n",
    "            and 3 <= len(self.required_skills) <= 6\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class ProjectSpecification:\n",
    "    \"\"\"Complete, machine-consumable project specification.\"\"\"\n",
    "    project_summary: str\n",
    "    project_type: List[str]\n",
    "    headcount: int\n",
    "    duration_months: int\n",
    "    roles: List[ProjectRole]\n",
    "    assumptions: List[str]\n",
    "    risks: List[str]\n",
    "\n",
    "    def validate(self) -> Dict:\n",
    "        errors = []\n",
    "        total_quota = sum(r.quota for r in self.roles)\n",
    "        if total_quota != self.headcount:\n",
    "            errors.append(f\"Quota sum ({total_quota}) != headcount ({self.headcount})\")\n",
    "        for role in self.roles:\n",
    "            if not role.validate():\n",
    "                errors.append(f\"Invalid role: {role.role}\")\n",
    "        if not self.project_type or len(self.project_type) == 0:\n",
    "            errors.append(\"project_type cannot be empty\")\n",
    "        return {\"is_valid\": len(errors) == 0, \"errors\": errors}\n",
    "\n",
    "    @staticmethod\n",
    "    def to_dict(spec: 'ProjectSpecification') -> Dict:\n",
    "        \"\"\"Convert ProjectSpecification to dictionary.\"\"\"\n",
    "        return {\n",
    "            \"project_summary\": spec.project_summary,\n",
    "            \"project_type\": spec.project_type,\n",
    "            \"headcount\": spec.headcount,\n",
    "            \"duration_months\": spec.duration_months,\n",
    "            \"roles\": [\n",
    "                {\n",
    "                    \"role\": r.role,\n",
    "                    \"quota\": r.quota,\n",
    "                    \"responsibility\": r.responsibility,\n",
    "                    \"required_skills\": r.required_skills\n",
    "                }\n",
    "                for r in spec.roles\n",
    "            ],\n",
    "            \"assumptions\": spec.assumptions,\n",
    "            \"risks\": spec.risks\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class ConversationState:\n",
    "    messages: List[Dict] = field(default_factory=list)\n",
    "    current_intent: Optional[str] = None\n",
    "    extracted_project: Optional[ProjectSpecification] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    students_df: Optional[pd.DataFrame] = None \n",
    "    project_spec: Optional[ProjectSpecification] = None\n",
    "    project_row: Optional[pd.Series] = None  # optional / legacy\n",
    "    ranked_df: Optional[Dict[str, pd.DataFrame]] = None\n",
    "    decision_df: Optional[Dict[str, pd.DataFrame]] = None\n",
    "    capacity_ledger: Dict[str, int] = field(default_factory=dict)\n",
    "    assigned_in_project: set = field(default_factory=set)\n",
    "    upskill_df: Optional[pd.DataFrame] = None\n",
    "    explanations: Optional[List[Dict]] = None\n",
    "    validations: Optional[pd.DataFrame] = None\n",
    "    conversation: ConversationState = field(default_factory=ConversationState)\n",
    "    flags: Dict[str, bool] = field(default_factory=dict)\n",
    "    steps: int = 0\n",
    "    done: bool = False\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class AgentStateView:\n",
    "    ranked: bool\n",
    "    decided: bool\n",
    "    explained: bool\n",
    "    validated: bool\n",
    "    needs_upskill: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f537e",
   "metadata": {},
   "source": [
    "## State Abstraction & Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f94fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_state_view(state: AgentState) -> AgentStateView:\n",
    "    needs_upskill = False\n",
    "\n",
    "    if isinstance(state.decision_df, dict):\n",
    "        for df in state.decision_df.values():\n",
    "            if df[\"decision\"].isin([\"UPSKILL\", \"REJECT\"]).any():\n",
    "                needs_upskill = True\n",
    "                break\n",
    "\n",
    "    return AgentStateView(\n",
    "        ranked=state.ranked_df is not None,\n",
    "        decided=state.decision_df is not None,\n",
    "        explained=state.explanations is not None,\n",
    "        validated=state.validations is not None,\n",
    "        needs_upskill=needs_upskill,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209e94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_ACTIONS = [\n",
    "    \"RANK\",\n",
    "    \"DECIDE\",\n",
    "    \"PERSIST\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca22837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_actions(view: AgentStateView) -> List[str]:\n",
    "    actions = []\n",
    "\n",
    "    if not view.ranked:\n",
    "        actions.append(\"RANK\")\n",
    "    elif not view.decided:\n",
    "        actions.append(\"DECIDE\")\n",
    "    else:\n",
    "        actions.append(\"PERSIST\")\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9657370",
   "metadata": {},
   "source": [
    "# 3. Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4580eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolRegistry:\n",
    "    def __init__(self):\n",
    "        self.tools = {}\n",
    "\n",
    "    def register(self, name: str, tool):\n",
    "        self.tools[name] = tool\n",
    "\n",
    "    def get(self, name: str):\n",
    "        return self.tools[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2153f",
   "metadata": {},
   "source": [
    "## Tool 1 : Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf19493",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABBR_MAP = {\n",
    "    \"ml\": \"machine learning\",\n",
    "    \"etl\": \"extract transform load\",\n",
    "    \"cv\": \"computer vision\",\n",
    "    \"nlp\": \"natural language processing\",\n",
    "    \"dl\": \"deep learning\",\n",
    "}\n",
    "\n",
    "def normalize_skill(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    tokens = re.split(r\"[,\\s]+\", text)\n",
    "    tokens = [ABBR_MAP.get(t, t) for t in tokens if t]\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0493f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkillEmbedderTool:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.cache: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    def embed_text(self, text: str) -> np.ndarray:\n",
    "        text = normalize_skill(text)\n",
    "        if text not in self.cache:\n",
    "            self.cache[text] = self.model.encode(\n",
    "                text,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "        return self.cache[text]\n",
    "\n",
    "    def embed_batch(self, texts: List[str]) -> List[np.ndarray]:\n",
    "        result = []\n",
    "        for t in texts:\n",
    "            result.append(self.embed_text(t))\n",
    "        return result\n",
    "    \n",
    "skill_embedder = SkillEmbedderTool(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "class SkillIndex:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        skill_csv_path: str,\n",
    "        embedder: SkillEmbedderTool,\n",
    "        cache_path: str = \"skill_index_cache.pkl\",\n",
    "    ):\n",
    "        self.embedder = embedder\n",
    "        self.cache_path = Path(cache_path)\n",
    "\n",
    "        # ---------- LOAD FROM CACHE ----------\n",
    "        if self.cache_path.exists():\n",
    "            print(\"âš¡ Loading cached SkillIndex ...\")\n",
    "            with open(self.cache_path, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "\n",
    "            self.df = data[\"df\"]\n",
    "            self.emb_matrix = data[\"emb_matrix\"]\n",
    "\n",
    "            print(f\"âœ“ SkillIndex loaded ({len(self.df)} skills)\")\n",
    "            return\n",
    "\n",
    "        # ---------- BUILD FROM SCRATCH (FIRST RUN ONLY) ----------\n",
    "        print(\"â³ Building SkillIndex (first run only) ...\")\n",
    "\n",
    "        self.df = pd.read_csv(skill_csv_path)\n",
    "\n",
    "        assert \"skill_id\" in self.df.columns\n",
    "        assert \"skill_name\" in self.df.columns\n",
    "\n",
    "        # normalize\n",
    "        self.df[\"skill_name_norm\"] = self.df[\"skill_name\"].apply(normalize_skill)\n",
    "\n",
    "        # embed ONCE\n",
    "        self.df[\"embedding\"] = self.df[\"skill_name_norm\"].apply(\n",
    "            self.embedder.embed_text\n",
    "        )\n",
    "\n",
    "        self.emb_matrix = np.vstack(self.df[\"embedding\"].values)\n",
    "\n",
    "        # drop embedding column (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¹€à¸à¹‡à¸šà¸‹à¹‰à¸³)\n",
    "        df_to_save = self.df.drop(columns=[\"embedding\"])\n",
    "\n",
    "        with open(self.cache_path, \"wb\") as f:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    \"df\": df_to_save,\n",
    "                    \"emb_matrix\": self.emb_matrix,\n",
    "                },\n",
    "                f\n",
    "            )\n",
    "\n",
    "        print(f\"âœ“ SkillIndex cached ({len(self.df)} skills)\")\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        raw_skill: str,\n",
    "        top_k: int = 5,\n",
    "        min_sim: float = 0.5,\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Map raw / noisy skill text to canonical skills\n",
    "        \"\"\"\n",
    "        q_emb = self.embedder.embed_text(raw_skill)\n",
    "\n",
    "        sims = self.emb_matrix @ q_emb\n",
    "        idx = np.argsort(-sims)[:top_k]\n",
    "\n",
    "        results = []\n",
    "        for i in idx:\n",
    "            if sims[i] < min_sim:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"skill_id\": self.df.iloc[i][\"skill_id\"],\n",
    "                \"skill_name\": self.df.iloc[i][\"skill_name\"],\n",
    "                \"score\": float(sims[i]),\n",
    "            })\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c60b3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Loading cached SkillIndex ...\n",
      "âœ“ SkillIndex loaded (9734 skills)\n"
     ]
    }
   ],
   "source": [
    "skill_index = SkillIndex(\n",
    "    skill_csv_path=\"skill_node.csv\",\n",
    "    embedder=skill_embedder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65eb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentRankerTool:\n",
    "    \"\"\"\n",
    "    Rank students per role using skill-level semantic matching + coverage\n",
    "    - score: max cosine similarity (à¹€à¸”à¸´à¸¡)\n",
    "    - avg_cosine_similarity: average cosine similarity (à¹€à¸žà¸´à¹ˆà¸¡)\n",
    "    \"\"\"\n",
    "\n",
    "    def rank_by_role(\n",
    "        self,\n",
    "        project_row: pd.Series,\n",
    "        students_df: pd.DataFrame\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "        role_rankings = {}\n",
    "\n",
    "        for role, required_skills in project_row[\"role_skill_map\"].items():\n",
    "\n",
    "            role_skill_embs = skill_embedder.embed_batch(required_skills)\n",
    "            rows = []\n",
    "\n",
    "            for _, student in students_df.iterrows():\n",
    "\n",
    "                student_skills = [\n",
    "                    normalize_skill(s)\n",
    "                    for s in student[\"skills_text\"].split(\",\")\n",
    "                    if s.strip()\n",
    "                ]\n",
    "\n",
    "                student_skill_embs = skill_embedder.embed_batch(student_skills)\n",
    "\n",
    "                # best similarity per required skill\n",
    "                sims = [\n",
    "                    max(np.dot(s_emb, r_emb) for s_emb in student_skill_embs)\n",
    "                    for r_emb in role_skill_embs\n",
    "                ]\n",
    "\n",
    "                # âœ… metric à¹€à¸”à¸´à¸¡ (à¸¢à¸±à¸‡à¹ƒà¸Šà¹‰à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ)\n",
    "                max_cos_sim = max(sims) if sims else 0.0\n",
    "\n",
    "                # âž• metric à¹ƒà¸«à¸¡à¹ˆ (holistic / KR1 / XAI)\n",
    "                avg_cos_sim = float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "                coverage = (\n",
    "                    sum(s >= 0.6 for s in sims) / len(sims)\n",
    "                    if sims else 0.0\n",
    "                )\n",
    "\n",
    "                rows.append({\n",
    "                    \"role\": role,\n",
    "                    \"student_id\": student[\"student_id\"],\n",
    "                    \"student_name\": student[\"name\"],\n",
    "                    \"student_skills_text\": student[\"skills_text\"],\n",
    "\n",
    "                    # à¹€à¸”à¸´à¸¡\n",
    "                    \"score\": round(max_cos_sim, 3),\n",
    "\n",
    "                    # à¹€à¸žà¸´à¹ˆà¸¡\n",
    "                    \"avg_cosine_similarity\": round(avg_cos_sim, 3),\n",
    "\n",
    "                    \"coverage\": round(coverage, 2),\n",
    "                    \"current_assignments\": student[\"current_assignments\"],\n",
    "                    \"max_capacity\": student[\"max_capacity\"]\n",
    "                })\n",
    "\n",
    "            role_rankings[role] = (\n",
    "                pd.DataFrame(rows)\n",
    "                .sort_values(\"score\", ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "        return role_rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2086da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ranker = StudentRankerTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984d81b",
   "metadata": {},
   "source": [
    "## Tool 1.5 : +1 assigned à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸™à¸—à¸µà¹ˆ accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bffef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool X: StudentAssignmentUpdater\n",
    "class StudentAssignmentUpdaterTool:\n",
    "    \"\"\"\n",
    "    TOOL: Update student's current_assignments in database\n",
    "    \"\"\"\n",
    "\n",
    "    def increment(self, student_id: str, delta: int = 1):\n",
    "        \"\"\"\n",
    "        This should call real DB in production.\n",
    "        For now: placeholder side-effect.\n",
    "        \"\"\"\n",
    "        print(f\"ðŸ“Œ [DB] Increment current_assignments for student {student_id} (+{delta})\")\n",
    "\n",
    "        # TODO: replace with real DB update\n",
    "        # e.g. UPDATE students SET current_assignments = current_assignments + 1 WHERE student_id = ...\n",
    "        \n",
    "assignment_updater = StudentAssignmentUpdaterTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5b390",
   "metadata": {},
   "source": [
    "## Tool 2 : XAI rule-based + llm à¸•à¸­à¸™ à¸–à¸²à¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc6dc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionMakerTool:\n",
    "\n",
    "    def __init__(self, max_projects: int = 5):\n",
    "        self.max_projects = max_projects\n",
    "\n",
    "    def apply_constraints(\n",
    "        self,\n",
    "        match_row: pd.Series,\n",
    "        project_row: pd.Series\n",
    "    ) -> Tuple[str, List[str]]:\n",
    "\n",
    "        min_score = float(project_row[\"min_score\"])\n",
    "\n",
    "        if match_row[\"score\"] < min_score:\n",
    "            return \"REJECT\", [\"Semantic match score below threshold\"]\n",
    "\n",
    "        if match_row[\"coverage\"] < 0.1:\n",
    "            return \"UPSKILL\", [\"Insufficient skill coverage\"]\n",
    "\n",
    "        return \"ACCEPT\", [\"Score and coverage meet project requirements\"]\n",
    "\n",
    "\n",
    "\n",
    "    def progressive_match(\n",
    "        self,\n",
    "        project_row: pd.Series,\n",
    "        ranked_df: pd.DataFrame,\n",
    "        capacity_ledger: Dict[str, int],\n",
    "        assigned_in_project,\n",
    "        assignment_updater,\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        quota = int(project_row[\"quota\"])\n",
    "        evaluated = []\n",
    "        accepted_count = 0\n",
    "\n",
    "        for _, row in ranked_df.iterrows():\n",
    "            student_id = row[\"student_id\"]\n",
    "            current = capacity_ledger.get(student_id, 0)\n",
    "            reason_codes = []\n",
    "\n",
    "            # ---------- HARD CONSTRAINTS ----------\n",
    "            if student_id in assigned_in_project:\n",
    "                decision = \"REJECT\"\n",
    "                reason_codes.append(\"ALREADY_ASSIGNED_IN_PROJECT\")\n",
    "\n",
    "            elif current >= self.max_projects:\n",
    "                decision = \"REJECT\"\n",
    "                reason_codes.append(\"SYSTEM_MAX_PROJECTS\")\n",
    "\n",
    "            elif current >= row[\"max_capacity\"]:\n",
    "                decision = \"REJECT\"\n",
    "                reason_codes.append(\"PERSONAL_MAX_CAPACITY\")\n",
    "\n",
    "            # ---------- SOFT / SCORE ----------\n",
    "            else:\n",
    "                tmp_decision, _ = self.apply_constraints(row, project_row)\n",
    "\n",
    "                if tmp_decision == \"REJECT\":\n",
    "                    decision = \"REJECT\"\n",
    "                    reason_codes.append(\"SCORE_BELOW_THRESHOLD\")\n",
    "\n",
    "                elif tmp_decision == \"UPSKILL\":\n",
    "                    decision = \"UPSKILL\"\n",
    "                    reason_codes.append(\"LOW_SKILL_COVERAGE\")\n",
    "\n",
    "                elif accepted_count < quota:\n",
    "                    decision = \"ACCEPT\"\n",
    "                else:\n",
    "                    decision = \"REJECT\"\n",
    "                    reason_codes.append(\"QUOTA_FILLED\")\n",
    "\n",
    "            # ---------- SIDE EFFECT ----------\n",
    "            if decision == \"ACCEPT\":\n",
    "                accepted_count += 1\n",
    "                assigned_in_project.add(student_id)\n",
    "                capacity_ledger[student_id] = current + 1\n",
    "                assignment_updater.increment(student_id)\n",
    "\n",
    "            evaluated.append({\n",
    "                **row.to_dict(),\n",
    "                \"decision\": decision,\n",
    "                \"reason_codes\": reason_codes\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be482f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_maker = DecisionMakerTool(max_projects=MAX_PROJECTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4c665",
   "metadata": {},
   "source": [
    "## Tool 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d85f6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionExplainerTool:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def explain_decision(self, context: Dict) -> str:\n",
    "        prompt = f\"\"\"\n",
    "à¸„à¸¸à¸“à¸„à¸·à¸­à¸£à¸°à¸šà¸š Explainable AI\n",
    "à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆà¸‚à¸­à¸‡à¸„à¸¸à¸“à¸„à¸·à¸­ \"à¸­à¸˜à¸´à¸šà¸²à¸¢à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸£à¸°à¸šà¸šà¸„à¸³à¸™à¸§à¸“à¹„à¸§à¹‰à¹à¸¥à¹‰à¸§\" à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n",
    "\n",
    "à¸à¸Žà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸—à¸³à¸•à¸²à¸¡à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸„à¸£à¹ˆà¸‡à¸„à¸£à¸±à¸”:\n",
    "1. à¸­à¸™à¸¸à¸à¸²à¸•à¹ƒà¸«à¹‰à¸à¸¥à¹ˆà¸²à¸§à¸–à¸¶à¸‡à¹€à¸‰à¸žà¸²à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ context à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n",
    "2. à¸«à¹‰à¸²à¸¡à¹€à¸žà¸´à¹ˆà¸¡ skill à¹ƒà¸«à¸¡à¹ˆ à¸«à¹‰à¸²à¸¡ paraphrase à¸«à¹‰à¸²à¸¡à¸•à¸µà¸„à¸§à¸²à¸¡à¹à¸—à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚\n",
    "3. matched_role_skills à¹à¸¥à¸° missing_role_skills à¸•à¹‰à¸­à¸‡à¸­à¸˜à¸´à¸šà¸²à¸¢à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£à¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸¡à¸²à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n",
    "4. required_optional_skills à¸«à¹‰à¸²à¸¡à¸™à¸³à¸¡à¸²à¹ƒà¸Šà¹‰à¹€à¸›à¹‡à¸™à¹€à¸«à¸•à¸¸à¸œà¸¥à¹ƒà¸™à¸à¸²à¸£à¸›à¸à¸´à¹€à¸ªà¸˜\n",
    "5. à¸«à¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µ system constraint à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸² \"à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸”à¸ˆà¸²à¸à¸£à¸°à¸šà¸š\"\n",
    "\n",
    "6. à¸à¸²à¸£à¸­à¸˜à¸´à¸šà¸²à¸¢ metric à¸•à¹‰à¸­à¸‡à¸—à¸³à¸•à¸²à¸¡à¸à¸Žà¸™à¸µà¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸„à¸£à¹ˆà¸‡à¸„à¸£à¸±à¸”:\n",
    "   - à¸«à¸²à¸ context à¸¡à¸µà¸„à¹ˆà¸² max_cosine_similarity\n",
    "     à¸•à¹‰à¸­à¸‡à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²à¹€à¸Šà¸´à¸‡à¸•à¸±à¸§à¹€à¸¥à¸‚ EXACT à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¹ƒà¸™ context\n",
    "   - à¸«à¸²à¸ context à¸¡à¸µà¸„à¹ˆà¸² avg_cosine_similarity\n",
    "     à¸•à¹‰à¸­à¸‡à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²à¹€à¸Šà¸´à¸‡à¸•à¸±à¸§à¹€à¸¥à¸‚ EXACT à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¹ƒà¸™ context\n",
    "   - âŒ à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰à¸„à¸³à¸§à¹ˆà¸² \"à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸\", \"à¹‚à¸”à¸¢à¸›à¸£à¸°à¸¡à¸²à¸“\", \"à¸„à¹ˆà¸­à¸™à¸‚à¹‰à¸²à¸‡à¸ªà¸¹à¸‡\"\n",
    "   - âŒ à¸«à¹‰à¸²à¸¡à¸­à¸˜à¸´à¸šà¸²à¸¢à¹à¸—à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚\n",
    "   - âŒ à¸«à¹‰à¸²à¸¡à¸«à¸¥à¸µà¸à¹€à¸¥à¸µà¹ˆà¸¢à¸‡à¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸²\n",
    "\n",
    "7. à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸‚à¸­à¸‡ metric (à¹ƒà¸Šà¹‰à¹€à¸žà¸·à¹ˆà¸­à¸­à¸˜à¸´à¸šà¸²à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™):\n",
    "   - max_cosine_similarity:\n",
    "     à¸£à¸°à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸—à¸±à¸à¸©à¸°à¸šà¸²à¸‡à¸£à¸²à¸¢à¸à¸²à¸£\n",
    "   - avg_cosine_similarity:\n",
    "     à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¹€à¸Šà¸´à¸‡à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸‚à¸­à¸‡à¸—à¸±à¸à¸©à¸°à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸•à¹‰à¸­à¸‡à¸à¸²à¸£\n",
    "   âŒ à¸«à¹‰à¸²à¸¡à¸„à¸³à¸™à¸§à¸“à¹€à¸žà¸´à¹ˆà¸¡ âŒ à¸«à¹‰à¸²à¸¡à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸Šà¸´à¸‡à¸•à¸±à¸”à¸ªà¸´à¸™\n",
    "\n",
    "à¸¥à¸³à¸”à¸±à¸šà¸à¸²à¸£à¸­à¸˜à¸´à¸šà¸²à¸¢ (à¸•à¹‰à¸­à¸‡à¸„à¸£à¸šà¸—à¸¸à¸à¸«à¸±à¸§à¸‚à¹‰à¸­):\n",
    "- à¸£à¸°à¸šà¸¸à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ (role)\n",
    "- à¹€à¸«à¸•à¸¸à¸œà¸¥à¸”à¹‰à¸²à¸™à¸—à¸±à¸à¸©à¸° (à¸•à¹‰à¸­à¸‡à¸à¸¥à¹ˆà¸²à¸§à¸–à¸¶à¸‡ max_cosine_similarity à¹à¸¥à¸° avg_cosine_similarity à¸«à¸²à¸à¸¡à¸µ)\n",
    "- à¹€à¸«à¸•à¸¸à¸œà¸¥à¸”à¹‰à¸²à¸™à¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸”à¸‚à¸­à¸‡à¸£à¸°à¸šà¸š\n",
    "- à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆ\n",
    "\n",
    "Context:\n",
    "{json.dumps(context, ensure_ascii=False, indent=2)}\n",
    "\n",
    "à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ bullet points à¸ à¸²à¸©à¸²à¹„à¸—à¸¢\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "        response = self.llm(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1000,\n",
    "            temperature=0.0\n",
    "        )\n",
    "\n",
    "        # normalize output\n",
    "        if response is None:\n",
    "            return \"à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¹„à¸”à¹‰à¹ƒà¸™à¸‚à¸“à¸°à¸™à¸µà¹‰\"\n",
    "\n",
    "        if isinstance(response, list):\n",
    "            first = response[0]\n",
    "            if isinstance(first, str):\n",
    "                return first.strip()\n",
    "            if isinstance(first, dict):\n",
    "                return first.get(\"content\", \"\").strip()\n",
    "\n",
    "        if isinstance(response, str):\n",
    "            return response.strip()\n",
    "\n",
    "        return \"à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¹„à¸”à¹‰à¹ƒà¸™à¸‚à¸“à¸°à¸™à¸µà¹‰\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4368487",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = DecisionExplainerTool(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f10055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REASON_CODE_DEFS = {\n",
    "    \"PERSONAL_MAX_CAPACITY\": (\n",
    "        \"à¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£à¸¡à¸µà¸ˆà¸³à¸™à¸§à¸™à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸—à¸µà¹ˆà¸à¸³à¸¥à¸±à¸‡à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸šà¸­à¸¢à¸¹à¹ˆà¸„à¸£à¸šà¸•à¸²à¸¡ \"\n",
    "        \"max_capacity à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡à¹„à¸§à¹‰ à¸ˆà¸¶à¸‡à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸£à¸±à¸šà¸‡à¸²à¸™à¹€à¸žà¸´à¹ˆà¸¡à¹„à¸”à¹‰\"\n",
    "    ),\n",
    "    \"SYSTEM_MAX_PROJECTS\": (\n",
    "        \"à¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£à¸–à¸¶à¸‡à¸ˆà¸³à¸™à¸§à¸™à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸—à¸µà¹ˆà¸£à¸°à¸šà¸šà¸­à¸™à¸¸à¸à¸²à¸•\"\n",
    "    ),\n",
    "    \"QUOTA_FILLED\": (\n",
    "        \"à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸™à¸µà¹‰à¸¡à¸µà¸œà¸¹à¹‰à¹„à¸”à¹‰à¸£à¸±à¸šà¸„à¸±à¸”à¹€à¸¥à¸·à¸­à¸à¸„à¸£à¸šà¸•à¸²à¸¡ quota à¹à¸¥à¹‰à¸§\"\n",
    "    ),\n",
    "    \"SCORE_BELOW_THRESHOLD\": (\n",
    "        \"à¸„à¸°à¹à¸™à¸™ semantic à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸²à¹€à¸à¸“à¸‘à¹Œà¸‚à¸±à¹‰à¸™à¸•à¹ˆà¸³à¸‚à¸­à¸‡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸™à¸µà¹‰\"\n",
    "    ),\n",
    "    \"LOW_SKILL_COVERAGE\": (\n",
    "        \"à¸„à¸§à¸²à¸¡à¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¸‚à¸­à¸‡à¸—à¸±à¸à¸©à¸°à¸•à¹ˆà¸³à¸à¸§à¹ˆà¸²à¹€à¸à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¸£à¸°à¸šà¸šà¸à¸³à¸«à¸™à¸”\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01cc988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xai_context(row: pd.Series, project_row: pd.Series, role: str) -> Dict:\n",
    "\n",
    "    # à¸ªà¸¡à¸¡à¸•à¸´: optional skill à¸¡à¸µà¸„à¸³à¸§à¹ˆà¸² \"(optional)\"\n",
    "    raw_required = project_row[\"role_skill_map\"][role]\n",
    "\n",
    "    required_core_skills = []\n",
    "    required_optional_skills = []\n",
    "\n",
    "    for s in raw_required:\n",
    "        if \"optional\" in s.lower():\n",
    "            required_optional_skills.append(s.replace(\"(optional)\", \"\").strip())\n",
    "        else:\n",
    "            required_core_skills.append(s)\n",
    "\n",
    "    student_skills = [\n",
    "        normalize_skill(s)\n",
    "        for s in row[\"student_skills_text\"].split(\",\")\n",
    "        if s.strip()\n",
    "    ]\n",
    "\n",
    "    matched_skills = []\n",
    "    missing_skills = []\n",
    "\n",
    "    for r_skill in required_core_skills:\n",
    "        r_emb = skill_embedder.embed_text(r_skill)\n",
    "\n",
    "        best_match = None\n",
    "        best_sim = 0.0\n",
    "\n",
    "        for s_skill in student_skills:\n",
    "            s_emb = skill_embedder.embed_text(s_skill)\n",
    "            sim = float(np.dot(r_emb, s_emb))\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_match = s_skill\n",
    "\n",
    "        if best_sim >= 0.6:\n",
    "            matched_skills.append({\n",
    "                \"required_skill\": r_skill,\n",
    "                \"matched_student_skill\": best_match,\n",
    "                \"similarity\": round(best_sim, 2),\n",
    "            })\n",
    "        else:\n",
    "            missing_skills.append(r_skill)\n",
    "\n",
    "    return {\n",
    "        \"student_name\": row[\"student_name\"],\n",
    "        \"role\": role,\n",
    "        \"decision\": row[\"decision\"],\n",
    "\n",
    "        \"score\": round(row[\"score\"], 3),\n",
    "        \"coverage\": round(row[\"coverage\"], 2),\n",
    "\n",
    "        # ðŸ”’ SKILL TRUTH ONLY\n",
    "        \"required_core_skills\": required_core_skills,\n",
    "        \"required_optional_skills\": required_optional_skills,\n",
    "        \"matched_role_skills\": matched_skills,\n",
    "        \"missing_role_skills\": missing_skills,\n",
    "\n",
    "        \"reason_codes\": row[\"reason_codes\"],\n",
    "        \"reason_code_definitions\": {\n",
    "            code: REASON_CODE_DEFS.get(code, \"\")\n",
    "            for code in row[\"reason_codes\"]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75897b",
   "metadata": {},
   "source": [
    "## Tool 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52ce6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateDecision(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Validate whether a decision is consistent WITHIN THE ROLE ONLY.\n",
    "\n",
    "    Rules:\n",
    "    - Judge only based on role_required_skills\n",
    "    - matched_role_skills / missing_role_skills\n",
    "    - Do NOT consider any other skills\n",
    "    \"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"Role-scoped decision context\")\n",
    "    verdict = dspy.OutputField(desc=\"One of: OK, SUSPICIOUS\")\n",
    "    comment = dspy.OutputField(\n",
    "        desc=\"Short reason (1-2 sentences), role-specific only\"\n",
    "    )\n",
    "\n",
    "class DecisionValidatorTool(dspy.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.validate = dspy.Predict(ValidateDecision)\n",
    "\n",
    "    def validate_decision(self, context: Dict) -> Tuple[str, str]:\n",
    "        result = self.validate(context=str(context))\n",
    "        return result.verdict, result.comment\n",
    "\n",
    "    def validate_batch(\n",
    "        self,\n",
    "        decision_df_by_role: Dict[str, pd.DataFrame],\n",
    "        project_row: pd.Series\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "        validation_results = []\n",
    "\n",
    "        for role, df in decision_df_by_role.items():\n",
    "            for _, row in df.iterrows():\n",
    "                if row[\"decision\"] == \"ACCEPT\":\n",
    "                    continue\n",
    "\n",
    "                context = self._build_context(row, project_row, role)\n",
    "                verdict, comment = self.validate_decision(context)\n",
    "\n",
    "                validation_results.append({\n",
    "                    \"student_id\": row[\"student_id\"],\n",
    "                    \"role\": role,\n",
    "                    \"decision\": row[\"decision\"],\n",
    "                    \"verdict\": verdict,\n",
    "                    \"comment\": comment\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(validation_results)\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_context(match_row, project_row, role):\n",
    "        xai_ctx = build_xai_context(match_row, project_row, role)\n",
    "\n",
    "        return {\n",
    "            \"role\": role,\n",
    "            \"decision\": xai_ctx[\"decision\"],\n",
    "            \"score\": xai_ctx[\"score\"],\n",
    "            \"coverage\": xai_ctx[\"coverage\"],\n",
    "            \"reason_codes\": xai_ctx[\"reason_codes\"],\n",
    "            \"role_required_skills\": xai_ctx[\"role_required_skills\"],\n",
    "            \"matched_role_skills\": xai_ctx[\"matched_role_skills\"],\n",
    "            \"missing_role_skills\": xai_ctx[\"missing_role_skills\"],\n",
    "        }\n",
    "\n",
    "\n",
    "validator = DecisionValidatorTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902af16",
   "metadata": {},
   "source": [
    "## Tool 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "793d5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendUpskill(dspy.Signature):\n",
    "    \"\"\"Recommend skill improvements based on student-project gap.\"\"\"\n",
    "    student_skills = dspy.InputField(desc=\"Current student skills\")\n",
    "    required_skills = dspy.InputField(desc=\"Project required skills\")\n",
    "    recommendation = dspy.OutputField(\n",
    "        desc=\"Concrete skill gap analysis and learning recommendation (2-3 bullet points)\"\n",
    "    )\n",
    "\n",
    "class UpskillCoachTool(dspy.Module):\n",
    "    \"\"\"\n",
    "    TOOL 6: Generates personalized upskilling recommendations.\n",
    "    For UPSKILL/REJECT decisions, proposes concrete learning path.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.recommend = dspy.ChainOfThought(RecommendUpskill)\n",
    "    \n",
    "    def generate_recommendation(self, student_skills: str, required_skills: str) -> str:\n",
    "        result = self.recommend(\n",
    "            student_skills=student_skills,\n",
    "            required_skills=required_skills\n",
    "        )\n",
    "        return result.recommendation\n",
    "    \n",
    "    def coach_batch(self, decision_df: pd.DataFrame, project_row: pd.Series) -> pd.DataFrame:\n",
    "\n",
    "        upskill_results = []\n",
    "\n",
    "        for _, row in decision_df.iterrows():\n",
    "            if row[\"decision\"] not in [\"UPSKILL\", \"REJECT\"]:\n",
    "                continue\n",
    "\n",
    "            recommendation = self.generate_recommendation(\n",
    "                student_skills=row[\"student_skills_text\"],\n",
    "                required_skills=project_row[\"required_skills_text\"]\n",
    "            )\n",
    "\n",
    "            upskill_results.append({\n",
    "                \"student_id\": row[\"student_id\"],\n",
    "                \"student_name\": row[\"student_name\"],\n",
    "                \"decision\": row[\"decision\"],\n",
    "                \"recommendation\": recommendation\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(upskill_results)\n",
    "\n",
    "upskill_coach = UpskillCoachTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659dcef",
   "metadata": {},
   "source": [
    "## Tool 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30448418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsPersisterTool:\n",
    "    \"\"\"\n",
    "    TOOL 7: Persists all matching results and artifacts.\n",
    "    Outputs: decisions.csv, accepted.csv, explanations.txt, upskill_plans.csv, summary.json\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, run_dir: str):\n",
    "        self.run_dir = run_dir\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "    def persist_decisions(self, decision_df: pd.DataFrame) -> str:\n",
    "        path = f\"{self.run_dir}/decisions.csv\"\n",
    "        decision_df.to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_accepted(self, decision_df: pd.DataFrame, project_row: pd.Series, run_id: str) -> str:\n",
    "        \"\"\"Save only accepted assignments.\"\"\"\n",
    "        accepted = decision_df[decision_df[\"decision\"] == \"ACCEPT\"].copy()\n",
    "        accepted[\"project_id\"] = project_row[\"project_id\"]\n",
    "        accepted[\"project_title\"] = project_row[\"title\"]\n",
    "        accepted[\"run_id\"] = run_id\n",
    "        \n",
    "        cols = [\"run_id\", \"project_id\", \"project_title\", \"student_id\", \"student_name\", \"score\"]\n",
    "        path = f\"{self.run_dir}/accepted.csv\"\n",
    "        accepted[cols].to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_explanations(self, explanations: List[Dict]) -> str:\n",
    "        path = f\"{self.run_dir}/explanations.txt\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for e in explanations:\n",
    "                explanation = e.get(\"explanation\")\n",
    "                if not explanation:\n",
    "                    continue \n",
    "                f.write(f\"[{e['decision']}] Student {e['student_id']}\\n\")\n",
    "                f.write(explanation.strip() + \"\\n\\n\")\n",
    "        return path\n",
    "\n",
    "    \n",
    "    def persist_validations(self, validation_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save validation results (SUSPICIOUS decisions only).\"\"\"\n",
    "        suspicious = validation_df[validation_df[\"verdict\"] == \"SUSPICIOUS\"]\n",
    "        if suspicious.empty:\n",
    "            return None\n",
    "        \n",
    "        path = f\"{self.run_dir}/validation_alerts.txt\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for _, row in suspicious.iterrows():\n",
    "                f.write(\n",
    "                    f\"[SUSPICIOUS] Student {row['student_id']} \"\n",
    "                    f\"(decision={row['decision']}): {row['comment']}\\n\"\n",
    "                )\n",
    "        return path\n",
    "    \n",
    "    def persist_upskill_plans(self, upskill_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save upskilling recommendations.\"\"\"\n",
    "        if upskill_df.empty:\n",
    "            return None\n",
    "        \n",
    "        path = f\"{self.run_dir}/upskill_plans.csv\"\n",
    "        upskill_df.to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_summary(self, project_row: pd.Series, decision_df: pd.DataFrame) -> str:\n",
    "        # summarize per student (not per role)\n",
    "        priority = {\"ACCEPT\": 3, \"UPSKILL\": 2, \"REJECT\": 1}\n",
    "\n",
    "        per_student = (\n",
    "            decision_df\n",
    "            .assign(p=decision_df[\"decision\"].map(priority))\n",
    "            .sort_values(\"p\", ascending=False)\n",
    "            .groupby(\"student_id\", as_index=False)\n",
    "            .first()\n",
    "        )\n",
    "\n",
    "        summary = {\n",
    "            \"project_id\": project_row[\"project_id\"],\n",
    "            \"project_title\": project_row[\"title\"],\n",
    "            \"role_quotas\": project_row[\"role_quota_map\"],\n",
    "            \"accepted_count\": int((per_student[\"decision\"] == \"ACCEPT\").sum()),\n",
    "            \"rejected_count\": int((per_student[\"decision\"] == \"REJECT\").sum()),\n",
    "            \"upskill_count\": int((per_student[\"decision\"] == \"UPSKILL\").sum()),\n",
    "        }\n",
    "\n",
    "        path = f\"{self.run_dir}/summary.json\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "        return path\n",
    "\n",
    "\n",
    "\n",
    "persister = ResultsPersisterTool(RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67669e41",
   "metadata": {},
   "source": [
    "# add tool in toolregistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ee1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_registry = ToolRegistry()\n",
    "tool_registry.register(\"rank\", student_ranker)\n",
    "tool_registry.register(\"update_assignment\", assignment_updater)\n",
    "tool_registry.register(\"decide\", decision_maker)\n",
    "tool_registry.register(\"explain\", explainer)\n",
    "tool_registry.register(\"validate\", validator)\n",
    "tool_registry.register(\"upskill\", upskill_coach)\n",
    "tool_registry.register(\"persist\", persister)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f84d48",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e3e71",
   "metadata": {},
   "source": [
    "## policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ae59790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectNextAction(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Select the next agent action based on current abstract state.\n",
    "    \"\"\"\n",
    "    state = dspy.InputField(desc=\"Current agent state (boolean flags)\")\n",
    "    allowed_actions = dspy.InputField(desc=\"List of allowed next actions\")\n",
    "    next_action = dspy.OutputField(\n",
    "        desc=\"Choose exactly ONE action from allowed_actions\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ActionPolicy:\n",
    "    def choose(self, state_view: AgentStateView, allowed: List[str]) -> str:\n",
    "        return allowed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bdb7ae",
   "metadata": {},
   "source": [
    "## agent exec à¸—à¸³à¸•à¸²à¸¡à¸„à¸³à¸ªà¸±à¹ˆà¸‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2c0d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionExecutor:\n",
    "\n",
    "    def __init__(self, tools: ToolRegistry):\n",
    "        self.tools = tools\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_by_capacity(students_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Hard filter: only students with available capacity.\"\"\"\n",
    "        return students_df[\n",
    "            students_df[\"current_assignments\"] < students_df[\"max_capacity\"]\n",
    "        ].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def execute(self, action: str, state: AgentState) -> AgentState:\n",
    "        action = action.upper()\n",
    "\n",
    "\n",
    "        if action == \"RANK\":\n",
    "            \n",
    "            state.ranked_df = self.tools.get(\"rank\").rank_by_role(\n",
    "                state.project_row,\n",
    "                state.students_df\n",
    "            )\n",
    "\n",
    "        elif action == \"DECIDE\":\n",
    "            decisions = {}\n",
    "\n",
    "            updater = self.tools.get(\"update_assignment\")\n",
    "\n",
    "            for role, ranked_df in state.ranked_df.items():\n",
    "                quota = state.project_row[\"role_quota_map\"][role]\n",
    "\n",
    "                df = self.tools.get(\"decide\").progressive_match(\n",
    "                    project_row=pd.Series({\n",
    "                        \"quota\": quota,\n",
    "                        \"min_score\": state.project_row[\"min_score\"]\n",
    "                    }),\n",
    "                    ranked_df=ranked_df,\n",
    "                    capacity_ledger=state.capacity_ledger,\n",
    "                    assigned_in_project=state.assigned_in_project,\n",
    "                    assignment_updater=updater\n",
    "                )\n",
    "\n",
    "                decisions[role] = df\n",
    "\n",
    "            state.decision_df = decisions\n",
    "\n",
    "\n",
    "\n",
    "        elif action == \"EXPLAIN\":\n",
    "            # EXPLAIN: Generate LLM explanations for non-accept decisions\n",
    "            explanations = []\n",
    "            for role, df in state.decision_df.items():\n",
    "                for _, row in df.iterrows():\n",
    "                    if row[\"decision\"] != \"ACCEPT\":\n",
    "                        ctx = build_xai_context(row, state.project_row, role)\n",
    "                        explanations.append({\n",
    "                            \"role\": role,\n",
    "                            \"student_id\": row[\"student_id\"],\n",
    "                            \"decision\": row[\"decision\"],\n",
    "                            \"explanation\": self.tools.get(\"explain\").explain_decision(ctx)\n",
    "                        })\n",
    "                state.explanations = explanations\n",
    "\n",
    "\n",
    "\n",
    "        elif action == \"VALIDATE\":\n",
    "            # VALIDATE: Check decision consistency\n",
    "            state.validations = self.tools.get(\"validate\").validate_batch(\n",
    "                state.decision_df, \n",
    "                state.project_row\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"UPSKILL\":\n",
    "            # UPSKILL: Generate learning recommendations for rejected/upskill students\n",
    "            state.upskill_df = self.tools.get(\"upskill\").coach_batch(\n",
    "                state.decision_df,\n",
    "                state.project_row\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"PERSIST\":\n",
    "            def flatten_decisions(decision_df_by_role: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "                frames = []\n",
    "                for role, df in decision_df_by_role.items():\n",
    "                    tmp = df.copy()\n",
    "                    tmp[\"role\"] = role\n",
    "                    frames.append(tmp)\n",
    "                return pd.concat(frames, ignore_index=True)\n",
    "            # PERSIST: Save all artifacts\n",
    "            persister = self.tools.get(\"persist\")\n",
    "            flat_df = flatten_decisions(state.decision_df)\n",
    "            \n",
    "            persister.persist_decisions(flat_df)\n",
    "            persister.persist_accepted(flat_df, state.project_row, RUN_ID)\n",
    "            persister.persist_summary(state.project_row, flat_df) \n",
    "\n",
    "            # if state.explanations:\n",
    "            #     persister.persist_explanations(state.explanations)\n",
    "\n",
    "            if state.validations is not None and not state.validations.empty:\n",
    "                persister.persist_validations(state.validations)\n",
    "\n",
    "            if state.upskill_df is not None and not state.upskill_df.empty:\n",
    "                persister.persist_upskill_plans(state.upskill_df)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e4c00",
   "metadata": {},
   "source": [
    "### à¹à¸›à¸¥à¸‡ freetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8d2c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractProjectSpec(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract structured project specification from ambiguous description.\n",
    "    MUST satisfy all validation constraints.\n",
    "    \"\"\"\n",
    "    project_description = dspy.InputField(desc=\"Unstructured project description\")\n",
    "    headcount = dspy.InputField(desc=\"Total number of people needed\")\n",
    "    duration = dspy.InputField(desc=\"Project duration (e.g., '3 months')\")\n",
    "\n",
    "    specification = dspy.OutputField(\n",
    "        desc=(\n",
    "            \"Return ONLY valid JSON with fields:\\n\"\n",
    "            \"- project_summary (string)\\n\"\n",
    "            \"- project_type (non-empty list of strings)\\n\"\n",
    "            \"- headcount (int, must equal input)\\n\"\n",
    "            \"- duration_months (int)\\n\"\n",
    "            \"- roles (list of objects, MUST NOT be empty)\\n\"\n",
    "            \"   Each role MUST have:\\n\"\n",
    "            \"     - role (non-empty string)\\n\"\n",
    "            \"     - quota (int >= 1)\\n\"\n",
    "            \"     - responsibility (non-empty string)\\n\"\n",
    "            \"     - required_skills (list of 3 to 6 strings)\\n\"\n",
    "            \"   Sum of all role.quota MUST equal headcount\\n\"\n",
    "            \"- assumptions (list of strings)\\n\"\n",
    "            \"- risks (list of strings)\\n\\n\"\n",
    "            \"If constraints cannot be met, ADJUST roles so that quota sum equals headcount.\\n\"\n",
    "            \"Do not include explanations. JSON only.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class ProjectExtractorTool(dspy.Module):\n",
    "    def __init__(self, max_retries: int = 2):\n",
    "        super().__init__()\n",
    "        self.extractor = dspy.Predict(ExtractProjectSpec)\n",
    "        self.max_retries = max_retries\n",
    "\n",
    "    def forward(self, project_description: str, headcount: int, duration: str) -> ProjectSpecification:\n",
    "        last_error = None\n",
    "\n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            result = self.extractor(\n",
    "                project_description=project_description,\n",
    "                headcount=headcount,\n",
    "                duration=duration\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                spec_json = self._parse_json(result.specification)\n",
    "                spec = self._build_specification(spec_json, headcount)\n",
    "                return spec\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "\n",
    "        raise ValueError(f\"Project extraction failed after retries: {last_error}\")\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_json(json_str: str) -> Dict:\n",
    "        \"\"\"Extract JSON object from LLM response.\"\"\"\n",
    "        cleaned = re.sub(r\"```(?:json)?\", \"\", json_str)\n",
    "        cleaned = cleaned.strip()\n",
    "        start = cleaned.find(\"{\")\n",
    "        if start == -1:\n",
    "            raise ValueError(\"No JSON object found\")\n",
    "        stack = []\n",
    "        end = None\n",
    "        for i in range(start, len(cleaned)):\n",
    "            if cleaned[i] == \"{\":\n",
    "                stack.append(\"{\")\n",
    "            elif cleaned[i] == \"}\":\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    end = i + 1\n",
    "                    break\n",
    "        if end is None:\n",
    "            raise ValueError(\"Unbalanced JSON braces\")\n",
    "        json_candidate = cleaned[start:end]\n",
    "        try:\n",
    "            return json.loads(json_candidate)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_specification(spec_dict: Dict, headcount: int) -> ProjectSpecification:\n",
    "        roles = []\n",
    "\n",
    "        for role_dict in spec_dict.get(\"roles\", []):\n",
    "            required_skills = role_dict.get(\"required_skills\", [])\n",
    "            if isinstance(required_skills, str):\n",
    "                required_skills = [s.strip() for s in required_skills.split(\",\") if s.strip()]\n",
    "\n",
    "            role = ProjectRole(\n",
    "                role=str(role_dict.get(\"role\", \"\")).strip().upper(),\n",
    "                quota=int(role_dict.get(\"quota\", 0)),\n",
    "                responsibility=str(role_dict.get(\"responsibility\", \"\")).strip(),\n",
    "                required_skills=required_skills\n",
    "            )\n",
    "            roles.append(role)\n",
    "\n",
    "        spec = ProjectSpecification(\n",
    "            project_summary=str(spec_dict.get(\"project_summary\", \"\")).strip(),\n",
    "            project_type=spec_dict.get(\"project_type\", []),\n",
    "            headcount=headcount,\n",
    "            duration_months=int(spec_dict.get(\"duration_months\", 0)),\n",
    "            roles=roles,\n",
    "            assumptions=spec_dict.get(\"assumptions\", []),\n",
    "            risks=spec_dict.get(\"risks\", [])\n",
    "        )\n",
    "\n",
    "        validation = spec.validate()\n",
    "        if not validation[\"is_valid\"]:\n",
    "            raise ValueError(f\"Specification validation failed: {validation['errors']}\")\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65705837",
   "metadata": {},
   "source": [
    "#### ============================================================\n",
    "### 8. AUTONOMOUS AGENT (DETERMINISTIC ORCHESTRATION)\n",
    "#### The agent is the main loop that:\n",
    "#### 1. Receives a ProjectSpecification and list of students\n",
    "#### 2. Delegates to tools via an executor\n",
    "#### 3. Follows a rule-based planner for deterministic ordering\n",
    "#### 4. Returns final matching decisions\n",
    "#### ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b512775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_spec_to_row(spec: ProjectSpecification) -> pd.Series:\n",
    "    role_skill_map = {}\n",
    "\n",
    "    for r in spec.roles:\n",
    "        canonical_skills = []\n",
    "\n",
    "        for raw_skill in r.required_skills:\n",
    "            hits = skill_index.search(raw_skill, top_k=3)\n",
    "\n",
    "            # à¹€à¸à¹‡à¸šà¸Šà¸·à¹ˆà¸­ canonical skill\n",
    "            canonical_skills.extend(\n",
    "                h[\"skill_name\"].lower() for h in hits\n",
    "            )\n",
    "\n",
    "        # dedup\n",
    "        role_skill_map[r.role.lower()] = list(set(canonical_skills))\n",
    "\n",
    "    role_quota_map = {\n",
    "        r.role.lower(): r.quota\n",
    "        for r in spec.roles\n",
    "    }\n",
    "\n",
    "    return pd.Series({\n",
    "        \"project_id\": \"P_CHAT\",\n",
    "        \"title\": spec.project_summary[:50],\n",
    "        \"description\": spec.project_summary,\n",
    "        \"role_skill_map\": role_skill_map,     \n",
    "        \"role_quota_map\": role_quota_map,\n",
    "        \"min_score\": 0.6\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a37e214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_legality(proposed: str, allowed: List[str]) -> str:\n",
    "    if proposed in allowed:\n",
    "        return proposed\n",
    "    return allowed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d1e9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutonomousMatchingAgent:\n",
    "    def __init__(self, policy, executor):\n",
    "        self.executor = executor\n",
    "        self.policy = policy\n",
    "\n",
    "    def run(self, project_spec, students_df):\n",
    "        project_row = project_spec_to_row(project_spec)\n",
    "\n",
    "        state = AgentState(\n",
    "            project_spec=project_spec,\n",
    "            project_row=project_row,\n",
    "            students_df=students_df,\n",
    "            capacity_ledger=dict(\n",
    "                zip(\n",
    "                    students_df[\"student_id\"],\n",
    "                    students_df[\"current_assignments\"]\n",
    "                )   \n",
    "            )\n",
    "        )      \n",
    "\n",
    "        max_steps = 10\n",
    "        while not state.done and state.steps < max_steps:\n",
    "            state.steps += 1\n",
    "\n",
    "            view = build_state_view(state)\n",
    "            allowed = legal_actions(view)\n",
    "            proposed = self.policy.choose(view, allowed)\n",
    "            action = enforce_legality(proposed, allowed)\n",
    "\n",
    "            state = self.executor.execute(action, state)\n",
    "\n",
    "            if action == \"PERSIST\":\n",
    "                state.done = True\n",
    "\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e761567",
   "metadata": {},
   "source": [
    "# interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bfe91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyIntent(dspy.Signature):\n",
    "    user_message = dspy.InputField()\n",
    "    intent = dspy.OutputField(\n",
    "        desc=\"One of: CREATE_PROJECT, RUN_MATCHING, ASK_EXPLANATION, MODIFY_CONSTRAINT, CHAT\"\n",
    "    )\n",
    "\n",
    "class IntentRouter(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.classifier = dspy.Predict(ClassifyIntent)\n",
    "        \n",
    "    def route(self, text: str, state: AgentState) -> str:\n",
    "        text_l = text.lower()\n",
    "\n",
    "        if state.flags.get(\"matched\") and text_l.startswith(\"à¸—à¸³à¹„à¸¡\"):\n",
    "            return \"ASK_EXPLANATION\"\n",
    "\n",
    "\n",
    "        if any(k in text_l for k in [\n",
    "            \"à¸¡à¸µà¹ƒà¸„à¸£à¸šà¹‰à¸²à¸‡\",\n",
    "            \"à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\",\n",
    "            \"à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸™à¸±à¸à¹€à¸£à¸µà¸¢à¸™\",\n",
    "            \"student à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\",\n",
    "            \"à¸™à¸±à¸à¹€à¸£à¸µà¸¢à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”\"\n",
    "        ]):\n",
    "            return \"LIST_STUDENTS\"\n",
    "\n",
    "\n",
    "        if state.flags.get(\"project_ready\") and any(k in text_l for k in [\"à¸ˆà¸±à¸”à¸—à¸µà¸¡\", \"assign\", \"match\", \"à¹€à¸£à¸´à¹ˆà¸¡\", \"run\"]):\n",
    "            return \"RUN_MATCHING\"\n",
    "\n",
    "        if any(k in text_l for k in [\"à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ\", \"project\", \"à¸—à¸³à¸£à¸°à¸šà¸š\", \"à¸­à¸¢à¸²à¸à¹„à¸”à¹‰\"]):\n",
    "            return \"CREATE_PROJECT\"\n",
    "\n",
    "        # fallback to LLM\n",
    "        return self.classifier(user_message=text).intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cf75f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_student_name(text: str) -> str:\n",
    "\n",
    "    text = text.replace(\"à¸—à¸³à¹„à¸¡\", \"\").replace(\"à¹„à¸¡à¹ˆà¸œà¹ˆà¸²à¸™\", \"\")\n",
    "    text = text.replace(\"à¹€à¸žà¸£à¸²à¸°à¸­à¸°à¹„à¸£\", \"\")\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c0aee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_student(decision_df_by_role, name):\n",
    "    for role, df in decision_df_by_role.items():\n",
    "        match = df[df[\"student_name\"].str.contains(name, case=False)]\n",
    "        if not match.empty:\n",
    "            return match.iloc[0], role\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec4eeeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_student(decision_df_by_role: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    # flatten role -> rows\n",
    "    flat = pd.concat(\n",
    "        df.assign(role=role)\n",
    "        for role, df in decision_df_by_role.items()\n",
    "    )\n",
    "\n",
    "    # priority: ACCEPT > UPSKILL > REJECT\n",
    "    priority = {\"ACCEPT\": 3, \"UPSKILL\": 2, \"REJECT\": 1}\n",
    "\n",
    "    final = (\n",
    "        flat.assign(p=flat[\"decision\"].map(priority))\n",
    "            .sort_values(\"p\", ascending=False)\n",
    "            .groupby(\"student_id\", as_index=False)\n",
    "            .first()\n",
    "    )\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc9eb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop(agent: AutonomousMatchingAgent, extractor: ProjectExtractorTool):\n",
    "\n",
    "    state = AgentState(students_df=students_df)\n",
    "    router = IntentRouter()\n",
    "\n",
    "    print(\"ðŸ¤– à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¹ˆà¸§à¸¢à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰ ðŸ˜Š\")\n",
    "\n",
    "    while True:\n",
    "        user_text = input(\"ðŸ‘¤ \")\n",
    "        if user_text.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        intent = router.route(user_text, state)\n",
    "\n",
    "        # --- Free chat (clarification loop) ---\n",
    "        if intent == \"CHAT\":\n",
    "            print(\"ðŸ¤– à¹€à¸¥à¹ˆà¸²à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸„à¸£à¹ˆà¸²à¸§ à¹† à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š à¹€à¸”à¸µà¹‹à¸¢à¸§à¸œà¸¡à¸ˆà¸±à¸”à¸à¸²à¸£à¹ƒà¸«à¹‰\")\n",
    "\n",
    "        # --- User describes project and we extract it ---\n",
    "        elif intent == \"CREATE_PROJECT\":\n",
    "            print(\"ðŸ¤– à¹‚à¸­à¹€à¸„à¸„à¸£à¸±à¸š à¸œà¸¡à¸ªà¸£à¸¸à¸›à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹ƒà¸«à¹‰à¸™à¸°\")\n",
    "            try:\n",
    "                spec = extractor(\n",
    "                    project_description=user_text,\n",
    "                    headcount=3,\n",
    "                    duration=\"3 months\"\n",
    "                )\n",
    "                \n",
    "                state.conversation.extracted_project = spec\n",
    "                state.flags[\"project_ready\"] = True\n",
    "\n",
    "                print(\"ðŸ¤– à¸œà¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸²à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸„à¸·à¸­:\")\n",
    "                print(json.dumps(ProjectSpecification.to_dict(spec), indent=2, ensure_ascii=False))\n",
    "\n",
    "                print(\"ðŸ¤– à¸–à¹‰à¸²à¹‚à¸­à¹€à¸„ à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸² 'à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹€à¸¥à¸¢' à¹„à¸”à¹‰à¸„à¸£à¸±à¸š\")\n",
    "            except Exception as e:\n",
    "                print(f\"ðŸ¤– à¸‚à¸­à¹‚à¸—à¸©à¸™à¸°à¸„à¸£à¸±à¸š à¸œà¸¡à¸ªà¸£à¸¸à¸›à¹„à¸¡à¹ˆà¹„à¸”à¹‰ ({e})\")\n",
    "\n",
    "        elif intent == \"RUN_MATCHING\":\n",
    "            if not state.conversation.extracted_project:\n",
    "                print(\"ðŸ¤– à¸‚à¸­à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸à¹ˆà¸­à¸™à¸™à¸°à¸„à¸£à¸±à¸š\")\n",
    "                continue\n",
    "\n",
    "            print(\"ðŸ¤– à¸à¸³à¸¥à¸±à¸‡à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¸„à¸£à¸±à¸š â³\")\n",
    "\n",
    "            final_state = agent.run(\n",
    "                project_spec=state.conversation.extracted_project,\n",
    "                students_df=students_df\n",
    "            )\n",
    "\n",
    "            state.flags[\"matched\"] = True\n",
    "            state.decision_df = final_state.decision_df\n",
    "            state.project_row = final_state.project_row\n",
    "\n",
    "            final_students = summarize_by_student(state.decision_df)\n",
    "\n",
    "            accepted_df = final_students[final_students[\"decision\"] == \"ACCEPT\"]\n",
    "            rejected = (final_students[\"decision\"] == \"REJECT\").sum()\n",
    "            upskill  = (final_students[\"decision\"] == \"UPSKILL\").sum()\n",
    "\n",
    "            print(\"ðŸ¤– à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š ðŸŽ‰\")\n",
    "            print(f\"âœ“ à¸¢à¸­à¸¡à¸£à¸±à¸š: {len(accepted_df)}\")\n",
    "            print(f\"âœ“ à¸›à¸à¸´à¹€à¸ªà¸˜: {rejected}\")\n",
    "            print(f\"âœ“ à¸­à¸šà¸£à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: {upskill}\")\n",
    "\n",
    "            if not accepted_df.empty:\n",
    "                print(\"\\nðŸ¤– à¸—à¸µà¸¡à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸šà¸„à¸±à¸”à¹€à¸¥à¸·à¸­à¸:\")\n",
    "                for _, row in accepted_df.iterrows():\n",
    "                    print(f\"- {row['student_name']} ({row['role']})\")\n",
    "            else:\n",
    "                print(\"\\nðŸ¤– à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸„à¸£à¸œà¹ˆà¸²à¸™à¸à¸²à¸£à¸„à¸±à¸”à¹€à¸¥à¸·à¸­à¸\")\n",
    "\n",
    "            print(\"\\nðŸ¤– à¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸£à¸¹à¹‰à¹€à¸«à¸•à¸¸à¸œà¸¥à¸‚à¸­à¸‡à¹ƒà¸„à¸£ à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸² 'à¸—à¸³à¹„à¸¡ <à¸Šà¸·à¹ˆà¸­>' à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š\")\n",
    "\n",
    "            \n",
    "        elif intent == \"LIST_STUDENTS\":\n",
    "            names = state.students_df[\"name\"].tolist()\n",
    "            print(\"ðŸ¤– à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸™à¸±à¸à¹€à¸£à¸µà¸¢à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:\")\n",
    "            for n in names:\n",
    "                print(\"-\", n)\n",
    "\n",
    "\n",
    "        elif intent == \"ASK_EXPLANATION\":\n",
    "            if not state.flags.get(\"matched\"):\n",
    "                print(\"ðŸ¤– à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š\")\n",
    "                continue\n",
    "\n",
    "            name = extract_student_name(user_text)\n",
    "            row, role = find_student(state.decision_df, name)\n",
    "\n",
    "            if row is None:\n",
    "                print(\"ðŸ¤– à¸œà¸¡à¸«à¸²à¸„à¸™à¸™à¸±à¹‰à¸™à¹„à¸¡à¹ˆà¹€à¸ˆà¸­à¸„à¸£à¸±à¸š\")\n",
    "                continue\n",
    "\n",
    "            ctx = build_xai_context(row, state.project_row, role)\n",
    "            explanation = explainer.explain_decision(ctx)\n",
    "\n",
    "            print(f\"ðŸ¤– à¹€à¸«à¸•à¸¸à¸œà¸¥à¸ªà¸³à¸«à¸£à¸±à¸š {row['student_name']}:\")\n",
    "            print(explanation)\n",
    "\n",
    "        else:\n",
    "            print(\"ðŸ¤– à¸œà¸¡à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆ à¸¥à¸­à¸‡à¸­à¸˜à¸´à¸šà¸²à¸¢à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹€à¸žà¸´à¹ˆà¸¡à¸­à¸µà¸à¸™à¸´à¸”à¹„à¸”à¹‰à¹„à¸«à¸¡à¸„à¸£à¸±à¸š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbcd78",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67cb8e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Planner, Executor, and Agent initialized.\n"
     ]
    }
   ],
   "source": [
    "executor = ActionExecutor(tool_registry)\n",
    "policy = ActionPolicy()\n",
    "\n",
    "agent = AutonomousMatchingAgent(\n",
    "    policy=policy,\n",
    "    executor=executor\n",
    ")\n",
    "\n",
    "print(\"âœ“ Planner, Executor, and Agent initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfbe5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¹ˆà¸§à¸¢à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰ ðŸ˜Š\n",
      "ðŸ¤– à¹€à¸¥à¹ˆà¸²à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸„à¸£à¹ˆà¸²à¸§ à¹† à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š à¹€à¸”à¸µà¹‹à¸¢à¸§à¸œà¸¡à¸ˆà¸±à¸”à¸à¸²à¸£à¹ƒà¸«à¹‰\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m extractor = ProjectExtractorTool()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mchat_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mchat_loop\u001b[39m\u001b[34m(agent, extractor)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ¤– à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¹ˆà¸§à¸¢à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰ ðŸ˜Š\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     user_text = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mðŸ‘¤ \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m user_text.lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/living_lab/living_lab/lib/python3.12/site-packages/ipykernel/kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/living_lab/living_lab/lib/python3.12/site-packages/ipykernel/kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "extractor = ProjectExtractorTool()\n",
    "chat_loop(agent, extractor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "living_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
