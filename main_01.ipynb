{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "669c1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict, field\n",
    "\n",
    "import dspy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0245b",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 1. DATA LOADING & MODEL CONFIG\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setup complete. Run ID: 2026-01-19_23-22-39\n",
      "‚úì Students: 8\n"
     ]
    }
   ],
   "source": [
    "students_df = pd.read_csv(\"students.csv\")\n",
    "\n",
    "# Configure LLM (Ollama or OpenAI)\n",
    "\n",
    "# api_base  = 'https://uneuphonious-inductionless-arvilla.ngrok-free.dev'\n",
    "\n",
    "\n",
    "# llm = dspy.LM(\n",
    "#     model=\"ollama/gemma3:27b\",\n",
    "#     api_base=api_base,\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=2000\n",
    "# )\n",
    "\n",
    "llm = dspy.LM(\n",
    "    model=\"ollama/ministral-3:8b\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "\n",
    "dspy.settings.configure(lm=llm)\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Setup logging\n",
    "RUN_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RUN_DIR = f\"logs/run_{RUN_ID}\"\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "\n",
    "MAX_PROJECTS = 5\n",
    "print(f\"‚úì Setup complete. Run ID: {RUN_ID}\")\n",
    "print(f\"‚úì Students: {len(students_df)}\")\n",
    "# print(f\"Projects: {len(projects_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae57bc",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 2. CORE DATA STRUCTURES (STATE)\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4f9d4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProjectRole:\n",
    "    \"\"\"Represents a single human role in a project.\"\"\"\n",
    "    role: str\n",
    "    quota: int\n",
    "    responsibility: str\n",
    "    required_skills: List[str]\n",
    "\n",
    "    def validate(self) -> bool:\n",
    "        return (\n",
    "            len(self.role.strip()) > 0\n",
    "            and self.quota > 0\n",
    "            and len(self.responsibility.strip()) > 0\n",
    "            and 3 <= len(self.required_skills) <= 6\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class ProjectSpecification:\n",
    "    \"\"\"Complete, machine-consumable project specification.\"\"\"\n",
    "    project_summary: str\n",
    "    project_type: List[str]\n",
    "    headcount: int\n",
    "    duration_months: int\n",
    "    roles: List[ProjectRole]\n",
    "    assumptions: List[str]\n",
    "    risks: List[str]\n",
    "\n",
    "    def validate(self) -> Dict:\n",
    "        errors = []\n",
    "        total_quota = sum(r.quota for r in self.roles)\n",
    "        if total_quota != self.headcount:\n",
    "            errors.append(f\"Quota sum ({total_quota}) != headcount ({self.headcount})\")\n",
    "        for role in self.roles:\n",
    "            if not role.validate():\n",
    "                errors.append(f\"Invalid role: {role.role}\")\n",
    "        if not self.project_type or len(self.project_type) == 0:\n",
    "            errors.append(\"project_type cannot be empty\")\n",
    "        return {\"is_valid\": len(errors) == 0, \"errors\": errors}\n",
    "\n",
    "    @staticmethod\n",
    "    def to_dict(spec: 'ProjectSpecification') -> Dict:\n",
    "        \"\"\"Convert ProjectSpecification to dictionary.\"\"\"\n",
    "        return {\n",
    "            \"project_summary\": spec.project_summary,\n",
    "            \"project_type\": spec.project_type,\n",
    "            \"headcount\": spec.headcount,\n",
    "            \"duration_months\": spec.duration_months,\n",
    "            \"roles\": [\n",
    "                {\n",
    "                    \"role\": r.role,\n",
    "                    \"quota\": r.quota,\n",
    "                    \"responsibility\": r.responsibility,\n",
    "                    \"required_skills\": r.required_skills\n",
    "                }\n",
    "                for r in spec.roles\n",
    "            ],\n",
    "            \"assumptions\": spec.assumptions,\n",
    "            \"risks\": spec.risks\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class ConversationState:\n",
    "    messages: List[Dict] = field(default_factory=list)\n",
    "    current_intent: Optional[str] = None\n",
    "    extracted_project: Optional[ProjectSpecification] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    students_df: Optional[pd.DataFrame] = None \n",
    "    project_spec: Optional[ProjectSpecification] = None\n",
    "    project_row: Optional[pd.Series] = None  # optional / legacy\n",
    "    ranked_df: Optional[Dict[str, pd.DataFrame]] = None\n",
    "    decision_df: Optional[Dict[str, pd.DataFrame]] = None\n",
    "    upskill_df: Optional[pd.DataFrame] = None\n",
    "    explanations: Optional[List[Dict]] = None\n",
    "    validations: Optional[pd.DataFrame] = None\n",
    "    conversation: ConversationState = field(default_factory=ConversationState)\n",
    "    flags: Dict[str, bool] = field(default_factory=dict)\n",
    "    steps: int = 0\n",
    "    done: bool = False\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class AgentStateView:\n",
    "    ranked: bool\n",
    "    decided: bool\n",
    "    explained: bool\n",
    "    validated: bool\n",
    "    needs_upskill: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f537e",
   "metadata": {},
   "source": [
    "## State Abstraction & Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "22f94fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_state_view(state: AgentState) -> AgentStateView:\n",
    "    needs_upskill = False\n",
    "\n",
    "    if isinstance(state.decision_df, dict):\n",
    "        for df in state.decision_df.values():\n",
    "            if df[\"decision\"].isin([\"UPSKILL\", \"REJECT\"]).any():\n",
    "                needs_upskill = True\n",
    "                break\n",
    "\n",
    "    return AgentStateView(\n",
    "        ranked=state.ranked_df is not None,\n",
    "        decided=state.decision_df is not None,\n",
    "        explained=state.explanations is not None,\n",
    "        validated=state.validations is not None,\n",
    "        needs_upskill=needs_upskill,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "209e94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_ACTIONS = [\n",
    "    \"RANK\",\n",
    "    \"DECIDE\",\n",
    "    \"EXPLAIN\",\n",
    "    \"VALIDATE\",\n",
    "    \"UPSKILL\",\n",
    "    \"PERSIST\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ca22837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_actions(view: AgentStateView) -> List[str]:\n",
    "    actions = []\n",
    "\n",
    "    if not view.ranked:\n",
    "        actions.append(\"RANK\")\n",
    "    elif not view.decided:\n",
    "        actions.append(\"DECIDE\")\n",
    "    elif not view.explained:\n",
    "        actions.append(\"EXPLAIN\")\n",
    "    # elif not view.validated:\n",
    "    #     actions.append(\"VALIDATE\")\n",
    "    # elif view.needs_upskill:\n",
    "    #     actions.append(\"UPSKILL\")\n",
    "    else:\n",
    "        actions.append(\"PERSIST\")\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9657370",
   "metadata": {},
   "source": [
    "# 3. TOOL REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5c4580eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolRegistry:\n",
    "    def __init__(self):\n",
    "        self.tools = {}\n",
    "\n",
    "    def register(self, name: str, tool):\n",
    "        self.tools[name] = tool\n",
    "\n",
    "    def get(self, name: str):\n",
    "        return self.tools[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2153f",
   "metadata": {},
   "source": [
    "## Tool 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9a0493f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkillEmbedderTool:\n",
    "    \"\"\"Tool 2: Creates semantic embeddings for skill texts.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_text(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Embed a single text (skill/requirement description).\"\"\"\n",
    "        return self.model.encode(text, normalize_embeddings=True)\n",
    "    \n",
    "    def embed_dataframe(self, df: pd.DataFrame, text_col: str) -> pd.DataFrame:\n",
    "        \"\"\"Add embedding column to dataframe.\"\"\"\n",
    "        result = df.copy()\n",
    "        result[\"embedding\"] = result[text_col].apply(self.embed_text)\n",
    "        return result\n",
    "\n",
    "skill_embedder = SkillEmbedderTool(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c65eb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentRankerTool:\n",
    "    \"\"\"\n",
    "    Rank students per ROLE using semantic similarity + coverage\n",
    "    \"\"\"\n",
    "\n",
    "    def rank_by_role(\n",
    "        self,\n",
    "        project_row: pd.Series,\n",
    "        students_df: pd.DataFrame\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "        role_rankings = {}\n",
    "\n",
    "        for role, skills in project_row[\"role_skill_map\"].items():\n",
    "            role_text = \", \".join(skills)\n",
    "            role_emb = skill_embedder.embed_text(role_text)\n",
    "\n",
    "            rows = []\n",
    "\n",
    "            for _, student in students_df.iterrows():\n",
    "                student_emb = skill_embedder.embed_text(student[\"skills_text\"])\n",
    "\n",
    "                score = float(cosine_similarity(\n",
    "                    [student_emb], [role_emb]\n",
    "                )[0][0])\n",
    "\n",
    "                coverage = self.compute_coverage(\n",
    "                    student[\"skills_text\"], skills\n",
    "                )\n",
    "\n",
    "                rows.append({\n",
    "                    \"role\": role,\n",
    "                    \"student_id\": student[\"student_id\"],\n",
    "                    \"student_name\": student[\"name\"],\n",
    "                    \"student_skills_text\": student[\"skills_text\"],\n",
    "                    \"score\": round(score, 3),\n",
    "                    \"coverage\": round(coverage, 2),\n",
    "                    \"current_assignments\": student[\"current_assignments\"],\n",
    "                    \"max_capacity\": student[\"max_capacity\"]\n",
    "                })\n",
    "\n",
    "            role_rankings[role] = (\n",
    "                pd.DataFrame(rows)\n",
    "                .sort_values(\"score\", ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "        return role_rankings\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_coverage(student_skills: str, required_skills: List[str]) -> float:\n",
    "        student_set = {s.strip().lower() for s in student_skills.split(\",\")}\n",
    "        required_set = set(required_skills)\n",
    "\n",
    "        if not required_set:\n",
    "            return 1.0\n",
    "\n",
    "        matched = sum(\n",
    "            1 for req in required_set\n",
    "            if any(req in s for s in student_set)\n",
    "        )\n",
    "\n",
    "        return matched / len(required_set)\n",
    "    \n",
    "student_ranker = StudentRankerTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5b390",
   "metadata": {},
   "source": [
    "## Tool 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fc6dc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionMakerTool:\n",
    "    \"\"\"\n",
    "    TOOL 3: Makes matching decisions based on hard & soft constraints.\n",
    "    Decisions: ACCEPT, UPSKILL, REJECT, WAITLIST\n",
    "    Hard constraints:\n",
    "      - Student capacity (current_assignments < max_capacity)\n",
    "      - Minimum score threshold\n",
    "    Soft constraints:\n",
    "      - Coverage threshold (50% of skills)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_projects: int = 5):\n",
    "        self.max_projects = max_projects\n",
    "    \n",
    "    def apply_constraints(self, match_row: pd.Series, project_row: pd.Series) -> Tuple[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Apply hard & soft constraints to a match.\n",
    "        \n",
    "        Returns:\n",
    "            (decision, rationale_list)\n",
    "        \"\"\"\n",
    "        min_score = float(project_row[\"min_score\"])\n",
    "        if match_row[\"score\"] < min_score:\n",
    "            return \"REJECT\", [\"Semantic match score below threshold\"]\n",
    "\n",
    "        if match_row[\"coverage\"] < 0.5:\n",
    "            return \"UPSKILL\", [\"Insufficient skill coverage\"]\n",
    "\n",
    "        return \"ACCEPT\", [\"Score and coverage meet project requirements\"]\n",
    "    \n",
    "    def progressive_match(\n",
    "        self, \n",
    "        project_row: pd.Series, \n",
    "        ranked_df: pd.DataFrame, \n",
    "        initial_k: int = 5, \n",
    "        step_k: int = 3\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Progressive matching: expand search window until quota is filled.\n",
    "        Prevents over-committing top candidates.\n",
    "        \n",
    "        Args:\n",
    "            project_row: Project specification\n",
    "            ranked_df: Pre-ranked students by score\n",
    "            initial_k: Initial candidate window\n",
    "            step_k: Expand window by this amount each iteration\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with decisions for all evaluated students\n",
    "        \"\"\"\n",
    "        quota = int(project_row[\"quota\"])\n",
    "        evaluated = []\n",
    "        accepted_count = 0\n",
    "        k = initial_k\n",
    "        seen = set()\n",
    "\n",
    "        while accepted_count < quota and k <= len(ranked_df):\n",
    "            batch = ranked_df.iloc[:k]\n",
    "\n",
    "            for _, row in batch.iterrows():\n",
    "                if row[\"student_id\"] in seen:\n",
    "                    continue\n",
    "                seen.add(row[\"student_id\"])\n",
    "\n",
    "                # Hard constraint: max projects capacity\n",
    "                if row[\"current_assignments\"] >= row[\"max_capacity\"]:\n",
    "                    decision, rationale = \"REJECT\", [\"Student reached max project limit\"]\n",
    "                else:\n",
    "                    decision, rationale = self.apply_constraints(row, project_row)\n",
    "\n",
    "                evaluated.append({\n",
    "                    **row.to_dict(),\n",
    "                    \"decision\": decision,\n",
    "                    \"rationale\": \"; \".join(rationale)\n",
    "                })\n",
    "\n",
    "                if decision == \"ACCEPT\":\n",
    "                    accepted_count += 1\n",
    "                    if accepted_count == quota:\n",
    "                        break\n",
    "\n",
    "            k += step_k\n",
    "\n",
    "        return pd.DataFrame(evaluated)\n",
    "    \n",
    "    def enforce_quota(self, decision_df: pd.DataFrame, project_row: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        After decisions made, move excess accepts to WAITLIST.\n",
    "        Ensures exact quota match.\n",
    "        \"\"\"\n",
    "        quota = int(project_row[\"quota\"])\n",
    "\n",
    "        accepted = (\n",
    "            decision_df[decision_df[\"decision\"] == \"ACCEPT\"]\n",
    "            .sort_values(\"score\", ascending=False)\n",
    "            .head(quota)\n",
    "        )\n",
    "\n",
    "        waitlist = (\n",
    "            decision_df[decision_df[\"decision\"] == \"ACCEPT\"]\n",
    "            .sort_values(\"score\", ascending=False)\n",
    "            .iloc[quota:]\n",
    "        )\n",
    "\n",
    "        final_df = decision_df.copy()\n",
    "        final_df.loc[waitlist.index, \"decision\"] = \"WAITLIST\"\n",
    "        final_df.loc[waitlist.index, \"rationale\"] = \"Quota exceeded; added to waitlist\"\n",
    "\n",
    "        return final_df\n",
    "\n",
    "decision_maker = DecisionMakerTool(max_projects=MAX_PROJECTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4c665",
   "metadata": {},
   "source": [
    "## Tool 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d85f6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainDecision(dspy.Signature):\n",
    "    \"\"\"Explain why the matching agent made a decision for a student-project pair.\"\"\"\n",
    "    context = dspy.InputField()\n",
    "    explanation = dspy.OutputField(desc=\"2-3 bullet points\")\n",
    "\n",
    "class DecisionExplainerTool(dspy.Module):\n",
    "    \"\"\"\n",
    "    TOOL 4: Generates LLM-based explanations for non-accept decisions.\n",
    "    Used to create human-readable rationales for UPSKILL/REJECT decisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.explain = dspy.ChainOfThought(ExplainDecision)\n",
    "    \n",
    "    def explain_decision(self, context: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Generate LLM explanation for a single decision.\n",
    "        \n",
    "        Args:\n",
    "            context: Structured decision context\n",
    "        \n",
    "        Returns:\n",
    "            LLM-generated explanation\n",
    "        \"\"\"\n",
    "        result = self.explain(context=str(context))\n",
    "        return result.explanation\n",
    "\n",
    "explainer = DecisionExplainerTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75897b",
   "metadata": {},
   "source": [
    "## Tool 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "52ce6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateDecision(dspy.Signature):\n",
    "    \"\"\"Validate whether decision is consistent with scores and context.\"\"\"\n",
    "    context = dspy.InputField(desc=\"Structured decision context\")\n",
    "    verdict = dspy.OutputField(desc=\"One of: OK, SUSPICIOUS\")\n",
    "    comment = dspy.OutputField(desc=\"Short reason explaining verdict (1-2 sentences)\")\n",
    "\n",
    "class DecisionValidatorTool(dspy.Module):\n",
    "    \"\"\"\n",
    "    TOOL 5: Validates matching decisions for consistency using LLM reasoning.\n",
    "    Checks if REJECT/UPSKILL decisions are consistent with scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.validate = dspy.Predict(ValidateDecision)\n",
    "    \n",
    "    def validate_decision(self, context: Dict) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Validate a single decision.\n",
    "        \n",
    "        Returns:\n",
    "            (verdict, comment) where verdict in {OK, SUSPICIOUS}\n",
    "        \"\"\"\n",
    "        result = self.validate(context=str(context))\n",
    "        return result.verdict, result.comment\n",
    "    \n",
    "    def validate_batch(self, decision_df: pd.DataFrame, project_row: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"Validate all non-ACCEPT decisions in a batch.\"\"\"\n",
    "        validation_results = []\n",
    "        \n",
    "        for _, row in decision_df.iterrows():\n",
    "            if row[\"decision\"] == \"ACCEPT\":\n",
    "                continue\n",
    "            context = self._build_context(row, project_row)\n",
    "            verdict, comment = self.validate_decision(context)\n",
    "            \n",
    "            validation_results.append({\n",
    "                \"student_id\": row[\"student_id\"],\n",
    "                \"decision\": row[\"decision\"],\n",
    "                \"verdict\": verdict,\n",
    "                \"comment\": comment\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(validation_results)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_context(match_row: pd.Series, project_row: pd.Series, role: str) -> Dict:\n",
    "        return {\n",
    "            \"project_title\": project_row[\"title\"],\n",
    "            \"project_description\": project_row[\"description\"],\n",
    "            \"project_role\": role,\n",
    "            \"project_required_skills\": \", \".join(project_row[\"role_skill_map\"][role]),\n",
    "            \"student_name\": match_row[\"student_name\"],\n",
    "            \"student_skills\": match_row[\"student_skills_text\"],\n",
    "            \"semantic_score\": round(match_row[\"score\"], 3),\n",
    "            \"skill_coverage\": round(match_row[\"coverage\"], 2),\n",
    "            \"decision\": match_row[\"decision\"],\n",
    "            \"rule_rationale\": match_row[\"rationale\"],\n",
    "        }\n",
    "\n",
    "validator = DecisionValidatorTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902af16",
   "metadata": {},
   "source": [
    "## Tool 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "793d5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendUpskill(dspy.Signature):\n",
    "    \"\"\"Recommend skill improvements based on student-project gap.\"\"\"\n",
    "    student_skills = dspy.InputField(desc=\"Current student skills\")\n",
    "    required_skills = dspy.InputField(desc=\"Project required skills\")\n",
    "    recommendation = dspy.OutputField(\n",
    "        desc=\"Concrete skill gap analysis and learning recommendation (2-3 bullet points)\"\n",
    "    )\n",
    "\n",
    "class UpskillCoachTool(dspy.Module):\n",
    "    \"\"\"\n",
    "    TOOL 6: Generates personalized upskilling recommendations.\n",
    "    For UPSKILL/REJECT decisions, proposes concrete learning path.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.recommend = dspy.ChainOfThought(RecommendUpskill)\n",
    "    \n",
    "    def generate_recommendation(self, student_skills: str, required_skills: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate upskill recommendation for a student.\n",
    "        \n",
    "        Args:\n",
    "            student_skills: Current student skills\n",
    "            required_skills: Project required skills\n",
    "        \n",
    "        Returns:\n",
    "            LLM-generated recommendation\n",
    "        \"\"\"\n",
    "        result = self.recommend(\n",
    "            student_skills=student_skills,\n",
    "            required_skills=required_skills\n",
    "        )\n",
    "        return result.recommendation\n",
    "    \n",
    "    def coach_batch(self, decision_df: pd.DataFrame, project_row: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate recommendations for all UPSKILL/REJECT decisions.\n",
    "        \n",
    "        Args:\n",
    "            decision_df: Decisions from DecisionMakerTool\n",
    "            project_row: Project specification\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with recommendations for non-accepted students\n",
    "        \"\"\"\n",
    "        upskill_results = []\n",
    "\n",
    "        for _, row in decision_df.iterrows():\n",
    "            if row[\"decision\"] not in [\"UPSKILL\", \"REJECT\"]:\n",
    "                continue\n",
    "\n",
    "            recommendation = self.generate_recommendation(\n",
    "                student_skills=row[\"student_skills_text\"],\n",
    "                required_skills=project_row[\"required_skills_text\"]\n",
    "            )\n",
    "\n",
    "            upskill_results.append({\n",
    "                \"student_id\": row[\"student_id\"],\n",
    "                \"student_name\": row[\"student_name\"],\n",
    "                \"decision\": row[\"decision\"],\n",
    "                \"recommendation\": recommendation\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(upskill_results)\n",
    "\n",
    "upskill_coach = UpskillCoachTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659dcef",
   "metadata": {},
   "source": [
    "## Tool 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "30448418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsPersisterTool:\n",
    "    \"\"\"\n",
    "    TOOL 7: Persists all matching results and artifacts.\n",
    "    Outputs: decisions.csv, accepted.csv, explanations.txt, upskill_plans.csv, summary.json\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, run_dir: str):\n",
    "        self.run_dir = run_dir\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "    def persist_decisions(self, decision_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save all matching decisions.\"\"\"\n",
    "        path = f\"{self.run_dir}/decisions.csv\"\n",
    "        decision_df.to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_accepted(self, decision_df: pd.DataFrame, project_row: pd.Series, run_id: str) -> str:\n",
    "        \"\"\"Save only accepted assignments.\"\"\"\n",
    "        accepted = decision_df[decision_df[\"decision\"] == \"ACCEPT\"].copy()\n",
    "        accepted[\"project_id\"] = project_row[\"project_id\"]\n",
    "        accepted[\"project_title\"] = project_row[\"title\"]\n",
    "        accepted[\"run_id\"] = run_id\n",
    "        \n",
    "        cols = [\"run_id\", \"project_id\", \"project_title\", \"student_id\", \"student_name\", \"score\"]\n",
    "        path = f\"{self.run_dir}/accepted.csv\"\n",
    "        accepted[cols].to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_explanations(self, explanations: List[Dict]) -> str:\n",
    "        \"\"\"Save LLM-generated explanations.\"\"\"\n",
    "        path = f\"{self.run_dir}/explanations.txt\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for e in explanations:\n",
    "                f.write(f\"[{e['decision']}] Student {e['student_id']}\\n\")\n",
    "                f.write(e[\"explanation\"].strip() + \"\\n\\n\")\n",
    "        return path\n",
    "    \n",
    "    def persist_validations(self, validation_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save validation results (SUSPICIOUS decisions only).\"\"\"\n",
    "        suspicious = validation_df[validation_df[\"verdict\"] == \"SUSPICIOUS\"]\n",
    "        if suspicious.empty:\n",
    "            return None\n",
    "        \n",
    "        path = f\"{self.run_dir}/validation_alerts.txt\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for _, row in suspicious.iterrows():\n",
    "                f.write(\n",
    "                    f\"[SUSPICIOUS] Student {row['student_id']} \"\n",
    "                    f\"(decision={row['decision']}): {row['comment']}\\n\"\n",
    "                )\n",
    "        return path\n",
    "    \n",
    "    def persist_upskill_plans(self, upskill_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save upskilling recommendations.\"\"\"\n",
    "        if upskill_df.empty:\n",
    "            return None\n",
    "        \n",
    "        path = f\"{self.run_dir}/upskill_plans.csv\"\n",
    "        upskill_df.to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_summary(self, project_row: pd.Series, decision_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save executive summary JSON.\"\"\"\n",
    "        accepted = decision_df[decision_df[\"decision\"] == \"ACCEPT\"]\n",
    "        rejected = decision_df[decision_df[\"decision\"] == \"REJECT\"]\n",
    "        upskill = decision_df[decision_df[\"decision\"] == \"UPSKILL\"]\n",
    "        \n",
    "        summary = {\n",
    "            \"project_id\": project_row[\"project_id\"],\n",
    "            \"project_title\": project_row[\"title\"],\n",
    "            \"quota\": project_row[\"quota\"],\n",
    "            \"accepted_count\": len(accepted),\n",
    "            \"accepted_students\": accepted[[\"student_id\", \"student_name\", \"score\"]].to_dict(\"records\"),\n",
    "            \"rejected_count\": len(rejected),\n",
    "            \"upskill_count\": len(upskill),\n",
    "        }\n",
    "        \n",
    "        path = f\"{self.run_dir}/summary.json\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        return path\n",
    "\n",
    "persister = ResultsPersisterTool(RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67669e41",
   "metadata": {},
   "source": [
    "# add tool in toolregistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "09ee1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_registry = ToolRegistry()\n",
    "tool_registry.register(\"rank\", student_ranker)\n",
    "tool_registry.register(\"decide\", decision_maker)\n",
    "tool_registry.register(\"explain\", explainer)\n",
    "tool_registry.register(\"validate\", validator)\n",
    "tool_registry.register(\"upskill\", upskill_coach)\n",
    "tool_registry.register(\"persist\", persister)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f84d48",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e3e71",
   "metadata": {},
   "source": [
    "## agent ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å action ‡∏ï‡πà‡∏≠‡πÑ‡∏õ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2ae59790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectNextAction(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Select the next agent action based on current abstract state.\n",
    "    \"\"\"\n",
    "    state = dspy.InputField(desc=\"Current agent state (boolean flags)\")\n",
    "    allowed_actions = dspy.InputField(desc=\"List of allowed next actions\")\n",
    "    next_action = dspy.OutputField(\n",
    "        desc=\"Choose exactly ONE action from allowed_actions\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ActionPolicy(dspy.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.select = dspy.Predict(SelectNextAction)\n",
    "\n",
    "    def choose(self, state_view: AgentStateView, allowed: List[str]) -> str:\n",
    "        result = self.select(\n",
    "            state=json.dumps(asdict(state_view)),\n",
    "            allowed_actions=json.dumps(allowed)\n",
    "        )\n",
    "        return result.next_action.strip().upper()\n",
    "    \n",
    "    \n",
    "def enforce_legality(action: str, allowed: List[str]) -> str:\n",
    "    if action not in allowed:\n",
    "        # fallback to deterministic safest action\n",
    "        return allowed[0]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bdb7ae",
   "metadata": {},
   "source": [
    "## agent exec ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a2c0d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionExecutor:\n",
    "\n",
    "    def __init__(self, tools: ToolRegistry):\n",
    "        self.tools = tools\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_by_capacity(students_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Hard filter: only students with available capacity.\"\"\"\n",
    "        return students_df[\n",
    "            students_df[\"current_assignments\"] < students_df[\"max_capacity\"]\n",
    "        ].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def execute(self, action: str, state: AgentState) -> AgentState:\n",
    "        action = action.upper()\n",
    "\n",
    "\n",
    "        if action == \"RANK\":\n",
    "            filtered = self.filter_by_capacity(state.students_df)\n",
    "\n",
    "            state.ranked_df = self.tools.get(\"rank\").rank_by_role(\n",
    "                state.project_row,\n",
    "                filtered\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"DECIDE\":\n",
    "            decisions = {}\n",
    "\n",
    "            for role, ranked_df in state.ranked_df.items():\n",
    "                quota = state.project_row[\"role_quota_map\"][role]\n",
    "\n",
    "                df = self.tools.get(\"decide\").progressive_match(\n",
    "                    project_row=pd.Series({\n",
    "                        \"quota\": quota,\n",
    "                        \"min_score\": state.project_row[\"min_score\"]\n",
    "                    }),\n",
    "                    ranked_df=ranked_df\n",
    "                )\n",
    "\n",
    "                decisions[role] = df\n",
    "\n",
    "            state.decision_df = decisions\n",
    "\n",
    "\n",
    "\n",
    "        elif action == \"EXPLAIN\":\n",
    "            # EXPLAIN: Generate LLM explanations for non-accept decisions\n",
    "            explanations = []\n",
    "            for role, df in state.decision_df.items():\n",
    "                for _, row in df.iterrows():\n",
    "                    if row[\"decision\"] != \"ACCEPT\":\n",
    "                        ctx = DecisionValidatorTool._build_context(row, state.project_row, role)\n",
    "                        explanations.append({\n",
    "                            \"role\": role,\n",
    "                            \"student_id\": row[\"student_id\"],\n",
    "                            \"decision\": row[\"decision\"],\n",
    "                            \"explanation\": self.tools.get(\"explain\").explain_decision(ctx)\n",
    "                        })\n",
    "                state.explanations = explanations\n",
    "\n",
    "\n",
    "\n",
    "        elif action == \"VALIDATE\":\n",
    "            # VALIDATE: Check decision consistency\n",
    "            state.validations = self.tools.get(\"validate\").validate_batch(\n",
    "                state.decision_df, \n",
    "                state.project_row\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"UPSKILL\":\n",
    "            # UPSKILL: Generate learning recommendations for rejected/upskill students\n",
    "            state.upskill_df = self.tools.get(\"upskill\").coach_batch(\n",
    "                state.decision_df,\n",
    "                state.project_row\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"PERSIST\":\n",
    "            # PERSIST: Save all artifacts\n",
    "            persister = self.tools.get(\"persist\")\n",
    "            for role, df in state.decision_df.items():\n",
    "                persister.persist_decisions(df)\n",
    "            persister.persist_accepted(state.decision_df, state.project_row, RUN_ID)\n",
    "\n",
    "            if state.explanations:\n",
    "                persister.persist_explanations(state.explanations)\n",
    "\n",
    "            if state.validations is not None and not state.validations.empty:\n",
    "                persister.persist_validations(state.validations)\n",
    "\n",
    "            if state.upskill_df is not None and not state.upskill_df.empty:\n",
    "                persister.persist_upskill_plans(state.upskill_df)\n",
    "\n",
    "            persister.persist_summary(state.project_row, state.decision_df)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e4c00",
   "metadata": {},
   "source": [
    "## agent ‡πÅ‡∏õ‡∏•‡∏á freetext ‡πÄ‡∏õ‡πá‡∏ô structure ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏•‡∏π‡∏õ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f8d2c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractProjectSpec(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract structured project specification from ambiguous description.\n",
    "    MUST satisfy all validation constraints.\n",
    "    \"\"\"\n",
    "    project_description = dspy.InputField(desc=\"Unstructured project description\")\n",
    "    headcount = dspy.InputField(desc=\"Total number of people needed\")\n",
    "    duration = dspy.InputField(desc=\"Project duration (e.g., '3 months')\")\n",
    "\n",
    "    specification = dspy.OutputField(\n",
    "        desc=(\n",
    "            \"Return ONLY valid JSON with fields:\\n\"\n",
    "            \"- project_summary (string)\\n\"\n",
    "            \"- project_type (non-empty list of strings)\\n\"\n",
    "            \"- headcount (int, must equal input)\\n\"\n",
    "            \"- duration_months (int)\\n\"\n",
    "            \"- roles (list of objects, MUST NOT be empty)\\n\"\n",
    "            \"   Each role MUST have:\\n\"\n",
    "            \"     - role (non-empty string)\\n\"\n",
    "            \"     - quota (int >= 1)\\n\"\n",
    "            \"     - responsibility (non-empty string)\\n\"\n",
    "            \"     - required_skills (list of 3 to 6 strings)\\n\"\n",
    "            \"   Sum of all role.quota MUST equal headcount\\n\"\n",
    "            \"- assumptions (list of strings)\\n\"\n",
    "            \"- risks (list of strings)\\n\\n\"\n",
    "            \"If constraints cannot be met, ADJUST roles so that quota sum equals headcount.\\n\"\n",
    "            \"Do not include explanations. JSON only.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class ProjectExtractorTool(dspy.Module):\n",
    "    def __init__(self, max_retries: int = 2):\n",
    "        super().__init__()\n",
    "        self.extractor = dspy.Predict(ExtractProjectSpec)\n",
    "        self.max_retries = max_retries\n",
    "\n",
    "    def forward(self, project_description: str, headcount: int, duration: str) -> ProjectSpecification:\n",
    "        last_error = None\n",
    "\n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            result = self.extractor(\n",
    "                project_description=project_description,\n",
    "                headcount=headcount,\n",
    "                duration=duration\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                spec_json = self._parse_json(result.specification)\n",
    "                spec = self._build_specification(spec_json, headcount)\n",
    "                return spec\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "\n",
    "        raise ValueError(f\"Project extraction failed after retries: {last_error}\")\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_json(json_str: str) -> Dict:\n",
    "        \"\"\"Extract JSON object from LLM response.\"\"\"\n",
    "        cleaned = re.sub(r\"```(?:json)?\", \"\", json_str)\n",
    "        cleaned = cleaned.strip()\n",
    "        start = cleaned.find(\"{\")\n",
    "        if start == -1:\n",
    "            raise ValueError(\"No JSON object found\")\n",
    "        stack = []\n",
    "        end = None\n",
    "        for i in range(start, len(cleaned)):\n",
    "            if cleaned[i] == \"{\":\n",
    "                stack.append(\"{\")\n",
    "            elif cleaned[i] == \"}\":\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    end = i + 1\n",
    "                    break\n",
    "        if end is None:\n",
    "            raise ValueError(\"Unbalanced JSON braces\")\n",
    "        json_candidate = cleaned[start:end]\n",
    "        try:\n",
    "            return json.loads(json_candidate)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_specification(spec_dict: Dict, headcount: int) -> ProjectSpecification:\n",
    "        roles = []\n",
    "\n",
    "        for role_dict in spec_dict.get(\"roles\", []):\n",
    "            required_skills = role_dict.get(\"required_skills\", [])\n",
    "            if isinstance(required_skills, str):\n",
    "                required_skills = [s.strip() for s in required_skills.split(\",\") if s.strip()]\n",
    "\n",
    "            role = ProjectRole(\n",
    "                role=str(role_dict.get(\"role\", \"\")).strip().upper(),\n",
    "                quota=int(role_dict.get(\"quota\", 0)),\n",
    "                responsibility=str(role_dict.get(\"responsibility\", \"\")).strip(),\n",
    "                required_skills=required_skills\n",
    "            )\n",
    "            roles.append(role)\n",
    "\n",
    "        spec = ProjectSpecification(\n",
    "            project_summary=str(spec_dict.get(\"project_summary\", \"\")).strip(),\n",
    "            project_type=spec_dict.get(\"project_type\", []),\n",
    "            headcount=headcount,\n",
    "            duration_months=int(spec_dict.get(\"duration_months\", 0)),\n",
    "            roles=roles,\n",
    "            assumptions=spec_dict.get(\"assumptions\", []),\n",
    "            risks=spec_dict.get(\"risks\", [])\n",
    "        )\n",
    "\n",
    "        validation = spec.validate()\n",
    "        if not validation[\"is_valid\"]:\n",
    "            raise ValueError(f\"Specification validation failed: {validation['errors']}\")\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65705837",
   "metadata": {},
   "source": [
    "#### ============================================================\n",
    "### 8. AUTONOMOUS AGENT (DETERMINISTIC ORCHESTRATION)\n",
    "#### The agent is the main loop that:\n",
    "#### 1. Receives a ProjectSpecification and list of students\n",
    "#### 2. Delegates to tools via an executor\n",
    "#### 3. Follows a rule-based planner for deterministic ordering\n",
    "#### 4. Returns final matching decisions\n",
    "#### ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8b512775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_spec_to_row(spec: ProjectSpecification) -> pd.Series:\n",
    "    role_skill_map = {\n",
    "        r.role.lower(): [s.lower() for s in r.required_skills]\n",
    "        for r in spec.roles\n",
    "    }\n",
    "\n",
    "    role_quota_map = {\n",
    "        r.role.lower(): r.quota\n",
    "        for r in spec.roles\n",
    "    }\n",
    "\n",
    "    return pd.Series({\n",
    "        \"project_id\": \"P_CHAT\",\n",
    "        \"title\": spec.project_summary[:50],\n",
    "        \"description\": spec.project_summary,\n",
    "        \"role_skill_map\": role_skill_map,     # ‚≠ê core\n",
    "        \"role_quota_map\": role_quota_map,     # ‚≠ê ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å\n",
    "        \"min_score\": 0.35\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9d1e9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutonomousMatchingAgent:\n",
    "    \"\"\"\n",
    "    The main agent that orchestrates matching decisions.\n",
    "    Uses a rule-based planner to determine next action.\n",
    "    Uses an executor to run actions and update state.\n",
    "    \n",
    "    Invariants:\n",
    "    - Agent never mutates global state\n",
    "    - All state transitions are deterministic\n",
    "    - LLM only used for explanation/validation/upskill (never for decisions)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, policy, executor):\n",
    "        self.executor = executor\n",
    "        self.policy = policy\n",
    "\n",
    "    def run(self, project_spec: ProjectSpecification, students_df: pd.DataFrame) -> AgentState:\n",
    "        \"\"\"\n",
    "        Run autonomous matching for a project.\n",
    "        \n",
    "        Args:\n",
    "            project_spec: Extracted project specification\n",
    "            students_df: DataFrame of all available students\n",
    "        \n",
    "        Returns:\n",
    "            Final AgentState with all matching decisions\n",
    "        \"\"\"\n",
    "        # Convert ProjectSpecification to project_row (pd.Series)\n",
    "        project_row = project_spec_to_row(project_spec)\n",
    "\n",
    "        # Initialize agent state\n",
    "        state = AgentState(\n",
    "            project_spec=project_spec,\n",
    "            project_row=project_row,\n",
    "            students_df=students_df\n",
    "        )\n",
    "\n",
    "        # Loop: planner chooses next action until done\n",
    "        max_steps = 10\n",
    "        while not state.done and state.steps < max_steps:\n",
    "            state.steps += 1\n",
    "\n",
    "            # 1) abstract state\n",
    "            view = build_state_view(state)\n",
    "\n",
    "            # 2) compute legal actions\n",
    "            allowed = legal_actions(view)\n",
    "\n",
    "            # 3) LLM chooses action\n",
    "            proposed = self.policy.choose(view, allowed)\n",
    "\n",
    "            # 4) legality guard\n",
    "            action = enforce_legality(proposed, allowed)\n",
    "\n",
    "            # 5) execute\n",
    "            state = self.executor.execute(action, state)\n",
    "\n",
    "            if action == \"PERSIST\":\n",
    "                state.done = True\n",
    "                \n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e761567",
   "metadata": {},
   "source": [
    "# interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9bfe91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyIntent(dspy.Signature):\n",
    "    user_message = dspy.InputField()\n",
    "    intent = dspy.OutputField(\n",
    "        desc=\"One of: CREATE_PROJECT, RUN_MATCHING, ASK_EXPLANATION, MODIFY_CONSTRAINT, CHAT\"\n",
    "    )\n",
    "\n",
    "class IntentRouter(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.classifier = dspy.Predict(ClassifyIntent)\n",
    "        \n",
    "    def route(self, text: str, state: AgentState) -> str:\n",
    "        text_l = text.lower()\n",
    "\n",
    "        # ‚úÖ hard rule first\n",
    "        if state.flags.get(\"project_ready\") and any(k in text_l for k in [\"‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°\", \"assign\", \"match\", \"‡πÄ‡∏£‡∏¥‡πà‡∏°\", \"run\"]):\n",
    "            return \"RUN_MATCHING\"\n",
    "\n",
    "        if any(k in text_l for k in [\"‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå\", \"project\", \"‡∏ó‡∏≥‡∏£‡∏∞‡∏ö‡∏ö\", \"‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ\"]):\n",
    "            return \"CREATE_PROJECT\"\n",
    "\n",
    "        # fallback to LLM\n",
    "        return self.classifier(user_message=text).intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bc9eb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop(agent: AutonomousMatchingAgent, extractor: ProjectExtractorTool):\n",
    "    \"\"\"\n",
    "    Interactive chatbot loop for project matching.\n",
    "    \n",
    "    Flow:\n",
    "    1. User describes project ‚Üí CREATE_PROJECT intent\n",
    "    2. Agent extracts ProjectSpecification\n",
    "    3. User triggers matching ‚Üí RUN_MATCHING intent\n",
    "    4. Agent autonomously matches students to roles\n",
    "    5. Results saved to RUN_DIR\n",
    "    \n",
    "    Args:\n",
    "        agent: AutonomousMatchingAgent instance\n",
    "        extractor: ProjectExtractorTool instance\n",
    "    \"\"\"\n",
    "    state = AgentState(students_df=students_df)\n",
    "    router = IntentRouter()\n",
    "\n",
    "    print(\"ü§ñ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°‡πÉ‡∏´‡πâ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÑ‡∏î‡πâ üòä\")\n",
    "\n",
    "    while True:\n",
    "        user_text = input(\"üë§ \")\n",
    "        if user_text.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        intent = router.route(user_text, state)\n",
    "\n",
    "        # --- Free chat (clarification loop) ---\n",
    "        if intent == \"CHAT\":\n",
    "            print(\"ü§ñ ‡πÄ‡∏•‡πà‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ú‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ\")\n",
    "\n",
    "        # --- User describes project and we extract it ---\n",
    "        elif intent == \"CREATE_PROJECT\":\n",
    "            print(\"ü§ñ ‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÉ‡∏´‡πâ‡∏ô‡∏∞\")\n",
    "            try:\n",
    "                spec = extractor(\n",
    "                    project_description=user_text,\n",
    "                    headcount=3,\n",
    "                    duration=\"3 months\"\n",
    "                )\n",
    "                \n",
    "                state.conversation.extracted_project = spec\n",
    "                state.flags[\"project_ready\"] = True\n",
    "\n",
    "                print(\"ü§ñ ‡∏ú‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ñ‡∏∑‡∏≠:\")\n",
    "                print(json.dumps(ProjectSpecification.to_dict(spec), indent=2, ensure_ascii=False))\n",
    "\n",
    "                print(\"ü§ñ ‡∏ñ‡πâ‡∏≤‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°‡πÄ‡∏•‡∏¢' ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö\")\n",
    "            except Exception as e:\n",
    "                print(f\"ü§ñ ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ({e})\")\n",
    "\n",
    "        # --- Trigger autonomous matching ---\n",
    "        elif intent == \"RUN_MATCHING\":\n",
    "            if not state.conversation.extracted_project:\n",
    "                print(\"ü§ñ ‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö\")\n",
    "                continue\n",
    "\n",
    "            print(\"ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‚è≥\")\n",
    "\n",
    "            final_state = agent.run(\n",
    "                project_spec=state.conversation.extracted_project,\n",
    "                students_df=students_df\n",
    "            )\n",
    "\n",
    "            accepted = 0\n",
    "            rejected = 0\n",
    "            upskill = 0\n",
    "            \n",
    "            for role, df in final_state.decision_df.items():\n",
    "                accepted += (df[\"decision\"] == \"ACCEPT\").sum()\n",
    "                rejected += (df[\"decision\"] == \"REJECT\").sum()\n",
    "                upskill += (df[\"decision\"] == \"UPSKILL\").sum()\n",
    "                \n",
    "            print(\"ü§ñ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö üéâ\")\n",
    "            print(f\"‚úì ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö: {accepted}\")\n",
    "            print(f\"‚úì ‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò: {rejected}\")\n",
    "            print(f\"‚úì ‡∏≠‡∏ö‡∏£‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {upskill}\")\n",
    "            print(f\"‚úì ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô: {RUN_DIR}\")\n",
    "\n",
    "        else:\n",
    "            print(\"ü§ñ ‡∏ú‡∏°‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡∏•‡∏≠‡∏á‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏µ‡∏Å‡∏ô‡∏¥‡∏î‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbcd78",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "67cb8e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Planner, Executor, and Agent initialized.\n"
     ]
    }
   ],
   "source": [
    "executor = ActionExecutor(tool_registry)\n",
    "policy = ActionPolicy()\n",
    "\n",
    "agent = AutonomousMatchingAgent(\n",
    "    policy=policy,\n",
    "    executor=executor\n",
    ")\n",
    "\n",
    "print(\"‚úì Planner, Executor, and Agent initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cfbe5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°‡πÉ‡∏´‡πâ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÑ‡∏î‡πâ üòä\n",
      "ü§ñ ‡πÇ‡∏≠‡πÄ‡∏Ñ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÉ‡∏´‡πâ‡∏ô‡∏∞\n",
      "ü§ñ ‡∏ú‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏Ñ‡∏∑‡∏≠:\n",
      "{\n",
      "  \"project_summary\": \"Development of an AI-powered birthday celebration platform with interactive features, automated gift suggestions, and personalized digital experiences for a virtual or hybrid birthday event.\",\n",
      "  \"project_type\": [\n",
      "    \"AI Development\",\n",
      "    \"Event Planning\",\n",
      "    \"Digital Experience\"\n",
      "  ],\n",
      "  \"headcount\": 3,\n",
      "  \"duration_months\": 3,\n",
      "  \"roles\": [\n",
      "    {\n",
      "      \"role\": \"AI/ML ENGINEER\",\n",
      "      \"quota\": 1,\n",
      "      \"responsibility\": \"Design and implement AI-driven features (e.g., chatbot for guest interactions, sentiment analysis for event feedback, or personalized birthday recommendations).\",\n",
      "      \"required_skills\": [\n",
      "        \"Python (TensorFlow/PyTorch)\",\n",
      "        \"Natural Language Processing (NLP)\",\n",
      "        \"API integration (REST/WebSocket)\",\n",
      "        \"Basic UI/UX prototyping\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"FRONTEND DEVELOPER\",\n",
      "      \"quota\": 1,\n",
      "      \"responsibility\": \"Build interactive web/mobile interfaces for the AI-powered birthday platform, including real-time updates, guest engagement tools, and digital invitations.\",\n",
      "      \"required_skills\": [\n",
      "        \"React.js/Next.js\",\n",
      "        \"JavaScript (ES6+)\",\n",
      "        \"WebSockets/Socket.io\",\n",
      "        \"UI/UX design principles\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"PROJECT COORDINATOR\",\n",
      "      \"quota\": 1,\n",
      "      \"responsibility\": \"Oversee project timelines, coordinate between teams, manage third-party integrations (e.g., payment gateways, calendar APIs), and ensure on-time delivery of features.\",\n",
      "      \"required_skills\": [\n",
      "        \"Agile/Scrum methodologies\",\n",
      "        \"Basic SQL/NoSQL database management\",\n",
      "        \"Stakeholder communication\",\n",
      "        \"Project management tools (Jira/Trello)\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"assumptions\": [\n",
      "    \"The birthday event is virtual or hybrid (online + limited in-person).\",\n",
      "    \"Existing tech stack includes cloud hosting (AWS/GCP) and basic backend services.\",\n",
      "    \"AI features will leverage pre-trained models with fine-tuning for the project‚Äôs specific use case.\",\n",
      "    \"Budget allows for third-party API integrations (e.g., payment, calendar sync).\"\n",
      "  ],\n",
      "  \"risks\": [\n",
      "    \"Delayed AI model training/testing due to dataset limitations or performance tuning requirements.\",\n",
      "    \"Frontend UI/UX misalignment with user expectations, requiring iterative redesigns.\",\n",
      "    \"Third-party API failures or rate limits impacting core features (e.g., guest registrations).\",\n",
      "    \"Scope creep from adding unexpected features (e.g., VR/AR elements) beyond initial planning.\"\n",
      "  ]\n",
      "}\n",
      "ü§ñ ‡∏ñ‡πâ‡∏≤‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°‡πÄ‡∏•‡∏¢' ‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö\n",
      "ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‚è≥\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'decision'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[177]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m extractor = ProjectExtractorTool()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mchat_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[175]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mchat_loop\u001b[39m\u001b[34m(agent, extractor)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ó‡∏µ‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‚è≥\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m final_state = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_spec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextracted_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstudents_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstudents_df\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m accepted = \u001b[32m0\u001b[39m\n\u001b[32m     66\u001b[39m rejected = \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mAutonomousMatchingAgent.run\u001b[39m\u001b[34m(self, project_spec, students_df)\u001b[39m\n\u001b[32m     53\u001b[39m action = enforce_legality(proposed, allowed)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# 5) execute\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m action == \u001b[33m\"\u001b[39m\u001b[33mPERSIST\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     59\u001b[39m     state.done = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[170]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mActionExecutor.execute\u001b[39m\u001b[34m(self, action, state)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m role, df \u001b[38;5;129;01min\u001b[39;00m state.decision_df.items():\n\u001b[32m     84\u001b[39m     persister.persist_decisions(df)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43mpersister\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpersist_accepted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecision_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproject_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRUN_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state.explanations:\n\u001b[32m     88\u001b[39m     persister.persist_explanations(state.explanations)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[167]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mResultsPersisterTool.persist_accepted\u001b[39m\u001b[34m(self, decision_df, project_row, run_id)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpersist_accepted\u001b[39m(\u001b[38;5;28mself\u001b[39m, decision_df: pd.DataFrame, project_row: pd.Series, run_id: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Save only accepted assignments.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     accepted = decision_df[\u001b[43mdecision_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m\"\u001b[39m\u001b[33mACCEPT\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m     20\u001b[39m     accepted[\u001b[33m\"\u001b[39m\u001b[33mproject_id\u001b[39m\u001b[33m\"\u001b[39m] = project_row[\u001b[33m\"\u001b[39m\u001b[33mproject_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     21\u001b[39m     accepted[\u001b[33m\"\u001b[39m\u001b[33mproject_title\u001b[39m\u001b[33m\"\u001b[39m] = project_row[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'decision'"
     ]
    }
   ],
   "source": [
    "extractor = ProjectExtractorTool()\n",
    "chat_loop(agent, extractor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "living_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
