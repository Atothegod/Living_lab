{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669c1d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atothegodd/living_lab/living_lab/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, asdict, field\n",
    "\n",
    "import dspy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0245b",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 1. DATA LOADING & MODEL CONFIG\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Setup complete. Run ID: 2026-01-22_17-11-33\n",
      "âœ“ Students: 8\n"
     ]
    }
   ],
   "source": [
    "students_df = pd.read_csv(\"students.csv\")\n",
    "\n",
    "# Configure LLM (Ollama or OpenAI)\n",
    "\n",
    "# api_base  = 'https://uneuphonious-inductionless-arvilla.ngrok-free.dev'\n",
    "\n",
    "\n",
    "# llm = dspy.LM(\n",
    "#     model=\"ollama/gemma3:27b\",\n",
    "#     api_base=api_base,\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=2000\n",
    "# )\n",
    "\n",
    "llm = dspy.LM(\n",
    "    model=\"ollama/ministral-3:8b\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "\n",
    "dspy.settings.configure(lm=llm)\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Setup logging\n",
    "RUN_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RUN_DIR = f\"logs/run_{RUN_ID}\"\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "\n",
    "MAX_PROJECTS = 5\n",
    "print(f\"âœ“ Setup complete. Run ID: {RUN_ID}\")\n",
    "print(f\"âœ“ Students: {len(students_df)}\")\n",
    "# print(f\"Projects: {len(projects_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae57bc",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# 2. CORE DATA STRUCTURES (STATE)\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProjectRole:\n",
    "    \"\"\"Represents a single human role in a project.\"\"\"\n",
    "    role: str\n",
    "    quota: int\n",
    "    responsibility: str\n",
    "    required_skills: List[str]\n",
    "\n",
    "    def validate(self) -> bool:\n",
    "        return (\n",
    "            len(self.role.strip()) > 0\n",
    "            and self.quota > 0\n",
    "            and len(self.responsibility.strip()) > 0\n",
    "            and 3 <= len(self.required_skills) <= 6\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class ProjectSpecification:\n",
    "    \"\"\"Complete, machine-consumable project specification.\"\"\"\n",
    "    project_summary: str\n",
    "    project_type: List[str]\n",
    "    headcount: int\n",
    "    duration_months: int\n",
    "    roles: List[ProjectRole]\n",
    "    assumptions: List[str]\n",
    "    risks: List[str]\n",
    "\n",
    "    def validate(self) -> Dict:\n",
    "        errors = []\n",
    "        total_quota = sum(r.quota for r in self.roles)\n",
    "        if total_quota != self.headcount:\n",
    "            errors.append(f\"Quota sum ({total_quota}) != headcount ({self.headcount})\")\n",
    "        for role in self.roles:\n",
    "            if not role.validate():\n",
    "                errors.append(f\"Invalid role: {role.role}\")\n",
    "        if not self.project_type or len(self.project_type) == 0:\n",
    "            errors.append(\"project_type cannot be empty\")\n",
    "        return {\"is_valid\": len(errors) == 0, \"errors\": errors}\n",
    "\n",
    "    @staticmethod\n",
    "    def to_dict(spec: 'ProjectSpecification') -> Dict:\n",
    "        \"\"\"Convert ProjectSpecification to dictionary.\"\"\"\n",
    "        return {\n",
    "            \"project_summary\": spec.project_summary,\n",
    "            \"project_type\": spec.project_type,\n",
    "            \"headcount\": spec.headcount,\n",
    "            \"duration_months\": spec.duration_months,\n",
    "            \"roles\": [\n",
    "                {\n",
    "                    \"role\": r.role,\n",
    "                    \"quota\": r.quota,\n",
    "                    \"responsibility\": r.responsibility,\n",
    "                    \"required_skills\": r.required_skills\n",
    "                }\n",
    "                for r in spec.roles\n",
    "            ],\n",
    "            \"assumptions\": spec.assumptions,\n",
    "            \"risks\": spec.risks\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class ConversationState:\n",
    "    messages: List[Dict] = field(default_factory=list)\n",
    "    current_intent: Optional[str] = None\n",
    "    extracted_project: Optional[ProjectSpecification] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    students_df: Optional[pd.DataFrame] = None \n",
    "    project_spec: Optional[ProjectSpecification] = None\n",
    "    project_row: Optional[pd.Series] = None  # optional / legacy\n",
    "    ranked_df: Optional[Dict[str, pd.DataFrame]] = None\n",
    "    decision_df: Optional[Dict[str, pd.DataFrame]] = None\n",
    "    upskill_df: Optional[pd.DataFrame] = None\n",
    "    explanations: Optional[List[Dict]] = None\n",
    "    validations: Optional[pd.DataFrame] = None\n",
    "    conversation: ConversationState = field(default_factory=ConversationState)\n",
    "    flags: Dict[str, bool] = field(default_factory=dict)\n",
    "    steps: int = 0\n",
    "    done: bool = False\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class AgentStateView:\n",
    "    ranked: bool\n",
    "    decided: bool\n",
    "    explained: bool\n",
    "    validated: bool\n",
    "    needs_upskill: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f537e",
   "metadata": {},
   "source": [
    "## State Abstraction & Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f94fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_state_view(state: AgentState) -> AgentStateView:\n",
    "    needs_upskill = False\n",
    "\n",
    "    if isinstance(state.decision_df, dict):\n",
    "        for df in state.decision_df.values():\n",
    "            if df[\"decision\"].isin([\"UPSKILL\", \"REJECT\"]).any():\n",
    "                needs_upskill = True\n",
    "                break\n",
    "\n",
    "    return AgentStateView(\n",
    "        ranked=state.ranked_df is not None,\n",
    "        decided=state.decision_df is not None,\n",
    "        explained=state.explanations is not None,\n",
    "        validated=state.validations is not None,\n",
    "        needs_upskill=needs_upskill,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_ACTIONS = [\n",
    "    \"RANK\",\n",
    "    \"DECIDE\",\n",
    "    \"PERSIST\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legal_actions(view: AgentStateView) -> List[str]:\n",
    "    actions = []\n",
    "\n",
    "    if not view.ranked:\n",
    "        actions.append(\"RANK\")\n",
    "    elif not view.decided:\n",
    "        actions.append(\"DECIDE\")\n",
    "    elif not view.explained:\n",
    "        actions.append(\"EXPLAIN\")\n",
    "    else:\n",
    "        actions.append(\"PERSIST\")\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9657370",
   "metadata": {},
   "source": [
    "# 3. TOOL REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4580eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolRegistry:\n",
    "    def __init__(self):\n",
    "        self.tools = {}\n",
    "\n",
    "    def register(self, name: str, tool):\n",
    "        self.tools[name] = tool\n",
    "\n",
    "    def get(self, name: str):\n",
    "        return self.tools[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2153f",
   "metadata": {},
   "source": [
    "## Tool 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf19493",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABBR_MAP = {\n",
    "    \"ml\": \"machine learning\",\n",
    "    \"etl\": \"extract transform load\",\n",
    "    \"cv\": \"computer vision\",\n",
    "    \"nlp\": \"natural language processing\",\n",
    "    \"dl\": \"deep learning\",\n",
    "}\n",
    "\n",
    "def normalize_skill(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    tokens = re.split(r\"[,\\s]+\", text)\n",
    "    tokens = [ABBR_MAP.get(t, t) for t in tokens if t]\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0493f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkillEmbedderTool:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.cache: Dict[str, np.ndarray] = {}\n",
    "\n",
    "    def embed_text(self, text: str) -> np.ndarray:\n",
    "        text = normalize_skill(text)\n",
    "        if text not in self.cache:\n",
    "            self.cache[text] = self.model.encode(\n",
    "                text,\n",
    "                normalize_embeddings=True\n",
    "            )\n",
    "        return self.cache[text]\n",
    "\n",
    "    def embed_batch(self, texts: List[str]) -> List[np.ndarray]:\n",
    "        result = []\n",
    "        for t in texts:\n",
    "            result.append(self.embed_text(t))\n",
    "        return result\n",
    "    \n",
    "skill_embedder = SkillEmbedderTool(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85f2b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Embedding skill_node.csv ...\n",
      "âœ“ SkillIndex ready (9734 skills)\n"
     ]
    }
   ],
   "source": [
    "class SkillIndex:\n",
    "    \"\"\"\n",
    "    Canonical skill index over skill_node.csv (10k skills)\n",
    "    Responsibilities:\n",
    "    - load + embed skill nodes ONCE\n",
    "    - semantic search raw skill â†’ canonical skills\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        skill_csv_path: str,\n",
    "        embedder: SkillEmbedderTool,\n",
    "    ):\n",
    "        self.embedder = embedder\n",
    "        self.df = pd.read_csv(skill_csv_path)\n",
    "\n",
    "        assert \"skill_id\" in self.df.columns\n",
    "        assert \"skill_name\" in self.df.columns\n",
    "\n",
    "        # normalize\n",
    "        self.df[\"skill_name_norm\"] = self.df[\"skill_name\"].apply(normalize_skill)\n",
    "\n",
    "        # embed once\n",
    "        print(\"â³ Embedding skill_node.csv ...\")\n",
    "        self.df[\"embedding\"] = self.df[\"skill_name_norm\"].apply(\n",
    "            self.embedder.embed_text\n",
    "        )\n",
    "\n",
    "        self.emb_matrix = np.vstack(self.df[\"embedding\"].values)  # (N, dim)\n",
    "\n",
    "        print(f\"âœ“ SkillIndex ready ({len(self.df)} skills)\")\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        raw_skill: str,\n",
    "        top_k: int = 5,\n",
    "        min_sim: float = 0.5,\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Map raw / noisy skill text to canonical skills\n",
    "        \"\"\"\n",
    "        q_emb = self.embedder.embed_text(raw_skill)\n",
    "\n",
    "        sims = self.emb_matrix @ q_emb  # dot product (cosine)\n",
    "        idx = np.argsort(-sims)[:top_k]\n",
    "\n",
    "        results = []\n",
    "        for i in idx:\n",
    "            if sims[i] < min_sim:\n",
    "                continue\n",
    "            results.append({\n",
    "                \"skill_id\": self.df.iloc[i][\"skill_id\"],\n",
    "                \"skill_name\": self.df.iloc[i][\"skill_name\"],\n",
    "                \"score\": float(sims[i]),\n",
    "            })\n",
    "\n",
    "        return results\n",
    "    \n",
    "skill_index = SkillIndex(\n",
    "    skill_csv_path=\"skill_node.csv\",\n",
    "    embedder=skill_embedder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65eb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentRankerTool:\n",
    "    \"\"\"\n",
    "    Rank students per role using skill-level semantic matching + coverage\n",
    "    \"\"\"\n",
    "\n",
    "    def rank_by_role(\n",
    "        self,\n",
    "        project_row: pd.Series,\n",
    "        students_df: pd.DataFrame\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "        role_rankings = {}\n",
    "\n",
    "        for role, required_skills in project_row[\"role_skill_map\"].items():\n",
    "\n",
    "            role_skill_embs = skill_embedder.embed_batch(required_skills)\n",
    "            rows = []\n",
    "\n",
    "            for _, student in students_df.iterrows():\n",
    "\n",
    "                student_skills = [\n",
    "                    normalize_skill(s)\n",
    "                    for s in student[\"skills_text\"].split(\",\")\n",
    "                    if s.strip()\n",
    "                ]\n",
    "\n",
    "                student_skill_embs = skill_embedder.embed_batch(student_skills)\n",
    "\n",
    "                sims = [\n",
    "                    max(np.dot(s_emb, r_emb) for s_emb in student_skill_embs)\n",
    "                    for r_emb in role_skill_embs\n",
    "                ]\n",
    "\n",
    "                score = max(sims)\n",
    "                coverage = sum(s >= 0.6 for s in sims) / len(sims) if sims else 0.0\n",
    "\n",
    "                rows.append({\n",
    "                    \"role\": role,\n",
    "                    \"student_id\": student[\"student_id\"],\n",
    "                    \"student_name\": student[\"name\"],\n",
    "                    \"student_skills_text\": student[\"skills_text\"],\n",
    "                    \"score\": round(score, 3),\n",
    "                    \"coverage\": round(coverage, 2),\n",
    "                    \"current_assignments\": student[\"current_assignments\"],\n",
    "                    \"max_capacity\": student[\"max_capacity\"]\n",
    "                })\n",
    "\n",
    "            role_rankings[role] = (\n",
    "                pd.DataFrame(rows)\n",
    "                .sort_values(\"score\", ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "        return role_rankings\n",
    "\n",
    "student_ranker = StudentRankerTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5b390",
   "metadata": {},
   "source": [
    "## Tool 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6dc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionMakerTool:\n",
    "    \"\"\"\n",
    "    TOOL 3: Makes matching decisions based on hard & soft constraints.\n",
    "    Decisions: ACCEPT, UPSKILL, REJECT, WAITLIST\n",
    "    Hard constraints:\n",
    "      - Student capacity (current_assignments < max_capacity)\n",
    "      - Minimum score threshold\n",
    "    Soft constraints:\n",
    "      - Coverage threshold (50% of skills)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_projects: int = 5):\n",
    "        self.max_projects = max_projects\n",
    "    \n",
    "    def apply_constraints(self, match_row: pd.Series, project_row: pd.Series) -> Tuple[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Apply hard & soft constraints to a match.\n",
    "        \n",
    "        Returns:\n",
    "            (decision, rationale_list)\n",
    "        \"\"\"\n",
    "        min_score = float(project_row[\"min_score\"])\n",
    "        if match_row[\"score\"] < min_score:\n",
    "            return \"REJECT\", [\"Semantic match score below threshold\"]\n",
    "\n",
    "        if match_row[\"coverage\"] < 0.1:\n",
    "            return \"UPSKILL\", [\"Insufficient skill coverage\"]\n",
    "\n",
    "        return \"ACCEPT\", [\"Score and coverage meet project requirements\"]\n",
    "    \n",
    "    def progressive_match(\n",
    "        self, \n",
    "        project_row: pd.Series, \n",
    "        ranked_df: pd.DataFrame, \n",
    "        initial_k: int = 5, \n",
    "        step_k: int = 3\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Progressive matching: expand search window until quota is filled.\n",
    "        Prevents over-committing top candidates.\n",
    "        \n",
    "        Args:\n",
    "            project_row: Project specification\n",
    "            ranked_df: Pre-ranked students by score\n",
    "            initial_k: Initial candidate window\n",
    "            step_k: Expand window by this amount each iteration\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with decisions for all evaluated students\n",
    "        \"\"\"\n",
    "        quota = int(project_row[\"quota\"])\n",
    "        evaluated = []\n",
    "        accepted_count = 0\n",
    "        k = initial_k\n",
    "        seen = set()\n",
    "\n",
    "        while accepted_count < quota and k <= len(ranked_df):\n",
    "            batch = ranked_df.iloc[:k]\n",
    "\n",
    "            for _, row in batch.iterrows():\n",
    "                if row[\"student_id\"] in seen:\n",
    "                    continue\n",
    "                seen.add(row[\"student_id\"])\n",
    "\n",
    "                # Hard constraint: max projects capacity\n",
    "                if row[\"current_assignments\"] >= row[\"max_capacity\"]:\n",
    "                    decision, rationale = \"REJECT\", [\"Student reached max project limit\"]\n",
    "                else:\n",
    "                    decision, rationale = self.apply_constraints(row, project_row)\n",
    "\n",
    "                evaluated.append({\n",
    "                    **row.to_dict(),\n",
    "                    \"decision\": decision,\n",
    "                    \"rationale\": \"; \".join(rationale)\n",
    "                })\n",
    "\n",
    "                if decision == \"ACCEPT\":\n",
    "                    accepted_count += 1\n",
    "                    if accepted_count == quota:\n",
    "                        break\n",
    "\n",
    "            k += step_k\n",
    "\n",
    "        return pd.DataFrame(evaluated)\n",
    "    \n",
    "    def enforce_quota(self, decision_df: pd.DataFrame, project_row: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        After decisions made, move excess accepts to WAITLIST.\n",
    "        Ensures exact quota match.\n",
    "        \"\"\"\n",
    "        quota = int(project_row[\"quota\"])\n",
    "\n",
    "        accepted = (\n",
    "            decision_df[decision_df[\"decision\"] == \"ACCEPT\"]\n",
    "            .sort_values(\"score\", ascending=False)\n",
    "            .head(quota)\n",
    "        )\n",
    "\n",
    "        waitlist = (\n",
    "            decision_df[decision_df[\"decision\"] == \"ACCEPT\"]\n",
    "            .sort_values(\"score\", ascending=False)\n",
    "            .iloc[quota:]\n",
    "        )\n",
    "\n",
    "        final_df = decision_df.copy()\n",
    "        final_df.loc[waitlist.index, \"decision\"] = \"WAITLIST\"\n",
    "        final_df.loc[waitlist.index, \"rationale\"] = \"Quota exceeded; added to waitlist\"\n",
    "\n",
    "        return final_df\n",
    "\n",
    "decision_maker = DecisionMakerTool(max_projects=MAX_PROJECTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4c665",
   "metadata": {},
   "source": [
    "## Tool 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainDecision(dspy.Signature):\n",
    "    \"\"\"Explain why the matching agent made a decision for a student-project pair.\"\"\"\n",
    "    context = dspy.InputField()\n",
    "    explanation = dspy.OutputField(desc=\"2-3 bullet points\")\n",
    "\n",
    "class DecisionExplainerTool(dspy.Module):\n",
    "    \"\"\"\n",
    "    TOOL 4: Generates LLM-based explanations for non-accept decisions.\n",
    "    Used to create human-readable rationales for UPSKILL/REJECT decisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.explain = dspy.ChainOfThought(ExplainDecision)\n",
    "    \n",
    "    def explain_decision(self, context: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Generate LLM explanation for a single decision.\n",
    "        \n",
    "        Args:\n",
    "            context: Structured decision context\n",
    "        \n",
    "        Returns:\n",
    "            LLM-generated explanation\n",
    "        \"\"\"\n",
    "        result = self.explain(context=str(context))\n",
    "        return result.explanation\n",
    "\n",
    "explainer = DecisionExplainerTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75897b",
   "metadata": {},
   "source": [
    "## Tool 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateDecision(dspy.Signature):\n",
    "    \"\"\"Validate whether decision is consistent with scores and context.\"\"\"\n",
    "    context = dspy.InputField(desc=\"Structured decision context\")\n",
    "    verdict = dspy.OutputField(desc=\"One of: OK, SUSPICIOUS\")\n",
    "    comment = dspy.OutputField(desc=\"Short reason explaining verdict (1-2 sentences)\")\n",
    "\n",
    "class DecisionValidatorTool(dspy.Module):\n",
    "    \"\"\"\n",
    "    TOOL 5: Validates matching decisions for consistency using LLM reasoning.\n",
    "    Checks if REJECT/UPSKILL decisions are consistent with scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.validate = dspy.Predict(ValidateDecision)\n",
    "    \n",
    "    def validate_decision(self, context: Dict) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Validate a single decision.\n",
    "        \n",
    "        Returns:\n",
    "            (verdict, comment) where verdict in {OK, SUSPICIOUS}\n",
    "        \"\"\"\n",
    "        result = self.validate(context=str(context))\n",
    "        return result.verdict, result.comment\n",
    "    \n",
    "    def validate_batch(self, decision_df: pd.DataFrame, project_row: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"Validate all non-ACCEPT decisions in a batch.\"\"\"\n",
    "        validation_results = []\n",
    "        \n",
    "        for _, row in decision_df.iterrows():\n",
    "            if row[\"decision\"] == \"ACCEPT\":\n",
    "                continue\n",
    "            context = self._build_context(row, project_row)\n",
    "            verdict, comment = self.validate_decision(context)\n",
    "            \n",
    "            validation_results.append({\n",
    "                \"student_id\": row[\"student_id\"],\n",
    "                \"decision\": row[\"decision\"],\n",
    "                \"verdict\": verdict,\n",
    "                \"comment\": comment\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(validation_results)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_context(match_row: pd.Series, project_row: pd.Series, role: str) -> Dict:\n",
    "        return {\n",
    "            \"project_title\": project_row[\"title\"],\n",
    "            \"project_description\": project_row[\"description\"],\n",
    "            \"project_role\": role,\n",
    "            \"project_required_skills\": \", \".join(project_row[\"role_skill_map\"][role]),\n",
    "            \"student_name\": match_row[\"student_name\"],\n",
    "            \"student_skills\": match_row[\"student_skills_text\"],\n",
    "            \"semantic_score\": round(match_row[\"score\"], 3),\n",
    "            \"skill_coverage\": round(match_row[\"coverage\"], 2),\n",
    "            \"decision\": match_row[\"decision\"],\n",
    "            \"rule_rationale\": match_row[\"rationale\"],\n",
    "        }\n",
    "\n",
    "validator = DecisionValidatorTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902af16",
   "metadata": {},
   "source": [
    "## Tool 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendUpskill(dspy.Signature):\n",
    "    \"\"\"Recommend skill improvements based on student-project gap.\"\"\"\n",
    "    student_skills = dspy.InputField(desc=\"Current student skills\")\n",
    "    required_skills = dspy.InputField(desc=\"Project required skills\")\n",
    "    recommendation = dspy.OutputField(\n",
    "        desc=\"Concrete skill gap analysis and learning recommendation (2-3 bullet points)\"\n",
    "    )\n",
    "\n",
    "class UpskillCoachTool(dspy.Module):\n",
    "    \"\"\"\n",
    "    TOOL 6: Generates personalized upskilling recommendations.\n",
    "    For UPSKILL/REJECT decisions, proposes concrete learning path.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.recommend = dspy.ChainOfThought(RecommendUpskill)\n",
    "    \n",
    "    def generate_recommendation(self, student_skills: str, required_skills: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate upskill recommendation for a student.\n",
    "        \n",
    "        Args:\n",
    "            student_skills: Current student skills\n",
    "            required_skills: Project required skills\n",
    "        \n",
    "        Returns:\n",
    "            LLM-generated recommendation\n",
    "        \"\"\"\n",
    "        result = self.recommend(\n",
    "            student_skills=student_skills,\n",
    "            required_skills=required_skills\n",
    "        )\n",
    "        return result.recommendation\n",
    "    \n",
    "    def coach_batch(self, decision_df: pd.DataFrame, project_row: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate recommendations for all UPSKILL/REJECT decisions.\n",
    "        \n",
    "        Args:\n",
    "            decision_df: Decisions from DecisionMakerTool\n",
    "            project_row: Project specification\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with recommendations for non-accepted students\n",
    "        \"\"\"\n",
    "        upskill_results = []\n",
    "\n",
    "        for _, row in decision_df.iterrows():\n",
    "            if row[\"decision\"] not in [\"UPSKILL\", \"REJECT\"]:\n",
    "                continue\n",
    "\n",
    "            recommendation = self.generate_recommendation(\n",
    "                student_skills=row[\"student_skills_text\"],\n",
    "                required_skills=project_row[\"required_skills_text\"]\n",
    "            )\n",
    "\n",
    "            upskill_results.append({\n",
    "                \"student_id\": row[\"student_id\"],\n",
    "                \"student_name\": row[\"student_name\"],\n",
    "                \"decision\": row[\"decision\"],\n",
    "                \"recommendation\": recommendation\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(upskill_results)\n",
    "\n",
    "upskill_coach = UpskillCoachTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659dcef",
   "metadata": {},
   "source": [
    "## Tool 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30448418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsPersisterTool:\n",
    "    \"\"\"\n",
    "    TOOL 7: Persists all matching results and artifacts.\n",
    "    Outputs: decisions.csv, accepted.csv, explanations.txt, upskill_plans.csv, summary.json\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, run_dir: str):\n",
    "        self.run_dir = run_dir\n",
    "        os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "    def persist_decisions(self, decision_df: pd.DataFrame) -> str:\n",
    "        path = f\"{self.run_dir}/decisions.csv\"\n",
    "        decision_df.to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_accepted(self, decision_df: pd.DataFrame, project_row: pd.Series, run_id: str) -> str:\n",
    "        \"\"\"Save only accepted assignments.\"\"\"\n",
    "        accepted = decision_df[decision_df[\"decision\"] == \"ACCEPT\"].copy()\n",
    "        accepted[\"project_id\"] = project_row[\"project_id\"]\n",
    "        accepted[\"project_title\"] = project_row[\"title\"]\n",
    "        accepted[\"run_id\"] = run_id\n",
    "        \n",
    "        cols = [\"run_id\", \"project_id\", \"project_title\", \"student_id\", \"student_name\", \"score\"]\n",
    "        path = f\"{self.run_dir}/accepted.csv\"\n",
    "        accepted[cols].to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_explanations(self, explanations: List[Dict]) -> str:\n",
    "        \"\"\"Save LLM-generated explanations.\"\"\"\n",
    "        path = f\"{self.run_dir}/explanations.txt\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for e in explanations:\n",
    "                f.write(f\"[{e['decision']}] Student {e['student_id']}\\n\")\n",
    "                f.write(e[\"explanation\"].strip() + \"\\n\\n\")\n",
    "        return path\n",
    "    \n",
    "    def persist_validations(self, validation_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save validation results (SUSPICIOUS decisions only).\"\"\"\n",
    "        suspicious = validation_df[validation_df[\"verdict\"] == \"SUSPICIOUS\"]\n",
    "        if suspicious.empty:\n",
    "            return None\n",
    "        \n",
    "        path = f\"{self.run_dir}/validation_alerts.txt\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for _, row in suspicious.iterrows():\n",
    "                f.write(\n",
    "                    f\"[SUSPICIOUS] Student {row['student_id']} \"\n",
    "                    f\"(decision={row['decision']}): {row['comment']}\\n\"\n",
    "                )\n",
    "        return path\n",
    "    \n",
    "    def persist_upskill_plans(self, upskill_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Save upskilling recommendations.\"\"\"\n",
    "        if upskill_df.empty:\n",
    "            return None\n",
    "        \n",
    "        path = f\"{self.run_dir}/upskill_plans.csv\"\n",
    "        upskill_df.to_csv(path, index=False)\n",
    "        return path\n",
    "    \n",
    "    def persist_summary(self, project_row: pd.Series, decision_df: pd.DataFrame) -> str:\n",
    "        summary = {\n",
    "            \"project_id\": project_row[\"project_id\"],\n",
    "            \"project_title\": project_row[\"title\"],\n",
    "            \"role_quotas\": project_row[\"role_quota_map\"],\n",
    "            \"accepted_count\": int((decision_df[\"decision\"] == \"ACCEPT\").sum()),\n",
    "            \"rejected_count\": int((decision_df[\"decision\"] == \"REJECT\").sum()),\n",
    "            \"upskill_count\": int((decision_df[\"decision\"] == \"UPSKILL\").sum()),\n",
    "        }\n",
    "\n",
    "        path = f\"{self.run_dir}/summary.json\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "        return path\n",
    "\n",
    "\n",
    "persister = ResultsPersisterTool(RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67669e41",
   "metadata": {},
   "source": [
    "# add tool in toolregistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_registry = ToolRegistry()\n",
    "tool_registry.register(\"rank\", student_ranker)\n",
    "tool_registry.register(\"decide\", decision_maker)\n",
    "tool_registry.register(\"explain\", explainer)\n",
    "tool_registry.register(\"validate\", validator)\n",
    "tool_registry.register(\"upskill\", upskill_coach)\n",
    "tool_registry.register(\"persist\", persister)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f84d48",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e3e71",
   "metadata": {},
   "source": [
    "## agent à¹€à¸¥à¸·à¸­à¸ action à¸•à¹ˆà¸­à¹„à¸›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae59790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectNextAction(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Select the next agent action based on current abstract state.\n",
    "    \"\"\"\n",
    "    state = dspy.InputField(desc=\"Current agent state (boolean flags)\")\n",
    "    allowed_actions = dspy.InputField(desc=\"List of allowed next actions\")\n",
    "    next_action = dspy.OutputField(\n",
    "        desc=\"Choose exactly ONE action from allowed_actions\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ActionPolicy:\n",
    "    def choose(self, state_view: AgentStateView, allowed: List[str]) -> str:\n",
    "        return allowed[0]  # deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bdb7ae",
   "metadata": {},
   "source": [
    "## agent exec à¸—à¸³à¸•à¸²à¸¡à¸„à¸³à¸ªà¸±à¹ˆà¸‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionExecutor:\n",
    "\n",
    "    def __init__(self, tools: ToolRegistry):\n",
    "        self.tools = tools\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_by_capacity(students_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Hard filter: only students with available capacity.\"\"\"\n",
    "        return students_df[\n",
    "            students_df[\"current_assignments\"] < students_df[\"max_capacity\"]\n",
    "        ].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def execute(self, action: str, state: AgentState) -> AgentState:\n",
    "        action = action.upper()\n",
    "\n",
    "\n",
    "        if action == \"RANK\":\n",
    "            filtered = self.filter_by_capacity(state.students_df)\n",
    "\n",
    "            state.ranked_df = self.tools.get(\"rank\").rank_by_role(\n",
    "                state.project_row,\n",
    "                filtered\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"DECIDE\":\n",
    "            decisions = {}\n",
    "\n",
    "            for role, ranked_df in state.ranked_df.items():\n",
    "                quota = state.project_row[\"role_quota_map\"][role]\n",
    "\n",
    "                df = self.tools.get(\"decide\").progressive_match(\n",
    "                    project_row=pd.Series({\n",
    "                        \"quota\": quota,\n",
    "                        \"min_score\": state.project_row[\"min_score\"]\n",
    "                    }),\n",
    "                    ranked_df=ranked_df\n",
    "                )\n",
    "\n",
    "                decisions[role] = df\n",
    "\n",
    "            state.decision_df = decisions\n",
    "\n",
    "\n",
    "\n",
    "        elif action == \"EXPLAIN\":\n",
    "            # EXPLAIN: Generate LLM explanations for non-accept decisions\n",
    "            explanations = []\n",
    "            for role, df in state.decision_df.items():\n",
    "                for _, row in df.iterrows():\n",
    "                    if row[\"decision\"] != \"ACCEPT\":\n",
    "                        ctx = DecisionValidatorTool._build_context(row, state.project_row, role)\n",
    "                        explanations.append({\n",
    "                            \"role\": role,\n",
    "                            \"student_id\": row[\"student_id\"],\n",
    "                            \"decision\": row[\"decision\"],\n",
    "                            \"explanation\": self.tools.get(\"explain\").explain_decision(ctx)\n",
    "                        })\n",
    "                state.explanations = explanations\n",
    "\n",
    "\n",
    "\n",
    "        elif action == \"VALIDATE\":\n",
    "            # VALIDATE: Check decision consistency\n",
    "            state.validations = self.tools.get(\"validate\").validate_batch(\n",
    "                state.decision_df, \n",
    "                state.project_row\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"UPSKILL\":\n",
    "            # UPSKILL: Generate learning recommendations for rejected/upskill students\n",
    "            state.upskill_df = self.tools.get(\"upskill\").coach_batch(\n",
    "                state.decision_df,\n",
    "                state.project_row\n",
    "            )\n",
    "\n",
    "\n",
    "        elif action == \"PERSIST\":\n",
    "            def flatten_decisions(decision_df_by_role: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "                frames = []\n",
    "                for role, df in decision_df_by_role.items():\n",
    "                    tmp = df.copy()\n",
    "                    tmp[\"role\"] = role\n",
    "                    frames.append(tmp)\n",
    "                return pd.concat(frames, ignore_index=True)\n",
    "            # PERSIST: Save all artifacts\n",
    "            persister = self.tools.get(\"persist\")\n",
    "            flat_df = flatten_decisions(state.decision_df)\n",
    "            \n",
    "            persister.persist_decisions(flat_df)\n",
    "            persister.persist_accepted(flat_df, state.project_row, RUN_ID)\n",
    "            persister.persist_summary(state.project_row, flat_df) \n",
    "\n",
    "            if state.explanations:\n",
    "                persister.persist_explanations(state.explanations)\n",
    "\n",
    "            if state.validations is not None and not state.validations.empty:\n",
    "                persister.persist_validations(state.validations)\n",
    "\n",
    "            if state.upskill_df is not None and not state.upskill_df.empty:\n",
    "                persister.persist_upskill_plans(state.upskill_df)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e4c00",
   "metadata": {},
   "source": [
    "## agent à¹à¸›à¸¥à¸‡ freetext à¹€à¸›à¹‡à¸™ structure à¸à¹ˆà¸­à¸™à¹€à¸‚à¹‰à¸²à¸¥à¸¹à¸›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractProjectSpec(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Extract structured project specification from ambiguous description.\n",
    "    MUST satisfy all validation constraints.\n",
    "    \"\"\"\n",
    "    project_description = dspy.InputField(desc=\"Unstructured project description\")\n",
    "    headcount = dspy.InputField(desc=\"Total number of people needed\")\n",
    "    duration = dspy.InputField(desc=\"Project duration (e.g., '3 months')\")\n",
    "\n",
    "    specification = dspy.OutputField(\n",
    "        desc=(\n",
    "            \"Return ONLY valid JSON with fields:\\n\"\n",
    "            \"- project_summary (string)\\n\"\n",
    "            \"- project_type (non-empty list of strings)\\n\"\n",
    "            \"- headcount (int, must equal input)\\n\"\n",
    "            \"- duration_months (int)\\n\"\n",
    "            \"- roles (list of objects, MUST NOT be empty)\\n\"\n",
    "            \"   Each role MUST have:\\n\"\n",
    "            \"     - role (non-empty string)\\n\"\n",
    "            \"     - quota (int >= 1)\\n\"\n",
    "            \"     - responsibility (non-empty string)\\n\"\n",
    "            \"     - required_skills (list of 3 to 6 strings)\\n\"\n",
    "            \"   Sum of all role.quota MUST equal headcount\\n\"\n",
    "            \"- assumptions (list of strings)\\n\"\n",
    "            \"- risks (list of strings)\\n\\n\"\n",
    "            \"If constraints cannot be met, ADJUST roles so that quota sum equals headcount.\\n\"\n",
    "            \"Do not include explanations. JSON only.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class ProjectExtractorTool(dspy.Module):\n",
    "    def __init__(self, max_retries: int = 2):\n",
    "        super().__init__()\n",
    "        self.extractor = dspy.Predict(ExtractProjectSpec)\n",
    "        self.max_retries = max_retries\n",
    "\n",
    "    def forward(self, project_description: str, headcount: int, duration: str) -> ProjectSpecification:\n",
    "        last_error = None\n",
    "\n",
    "        for attempt in range(self.max_retries + 1):\n",
    "            result = self.extractor(\n",
    "                project_description=project_description,\n",
    "                headcount=headcount,\n",
    "                duration=duration\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                spec_json = self._parse_json(result.specification)\n",
    "                spec = self._build_specification(spec_json, headcount)\n",
    "                return spec\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "\n",
    "        raise ValueError(f\"Project extraction failed after retries: {last_error}\")\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_json(json_str: str) -> Dict:\n",
    "        \"\"\"Extract JSON object from LLM response.\"\"\"\n",
    "        cleaned = re.sub(r\"```(?:json)?\", \"\", json_str)\n",
    "        cleaned = cleaned.strip()\n",
    "        start = cleaned.find(\"{\")\n",
    "        if start == -1:\n",
    "            raise ValueError(\"No JSON object found\")\n",
    "        stack = []\n",
    "        end = None\n",
    "        for i in range(start, len(cleaned)):\n",
    "            if cleaned[i] == \"{\":\n",
    "                stack.append(\"{\")\n",
    "            elif cleaned[i] == \"}\":\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    end = i + 1\n",
    "                    break\n",
    "        if end is None:\n",
    "            raise ValueError(\"Unbalanced JSON braces\")\n",
    "        json_candidate = cleaned[start:end]\n",
    "        try:\n",
    "            return json.loads(json_candidate)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_specification(spec_dict: Dict, headcount: int) -> ProjectSpecification:\n",
    "        roles = []\n",
    "\n",
    "        for role_dict in spec_dict.get(\"roles\", []):\n",
    "            required_skills = role_dict.get(\"required_skills\", [])\n",
    "            if isinstance(required_skills, str):\n",
    "                required_skills = [s.strip() for s in required_skills.split(\",\") if s.strip()]\n",
    "\n",
    "            role = ProjectRole(\n",
    "                role=str(role_dict.get(\"role\", \"\")).strip().upper(),\n",
    "                quota=int(role_dict.get(\"quota\", 0)),\n",
    "                responsibility=str(role_dict.get(\"responsibility\", \"\")).strip(),\n",
    "                required_skills=required_skills\n",
    "            )\n",
    "            roles.append(role)\n",
    "\n",
    "        spec = ProjectSpecification(\n",
    "            project_summary=str(spec_dict.get(\"project_summary\", \"\")).strip(),\n",
    "            project_type=spec_dict.get(\"project_type\", []),\n",
    "            headcount=headcount,\n",
    "            duration_months=int(spec_dict.get(\"duration_months\", 0)),\n",
    "            roles=roles,\n",
    "            assumptions=spec_dict.get(\"assumptions\", []),\n",
    "            risks=spec_dict.get(\"risks\", [])\n",
    "        )\n",
    "\n",
    "        validation = spec.validate()\n",
    "        if not validation[\"is_valid\"]:\n",
    "            raise ValueError(f\"Specification validation failed: {validation['errors']}\")\n",
    "\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65705837",
   "metadata": {},
   "source": [
    "#### ============================================================\n",
    "### 8. AUTONOMOUS AGENT (DETERMINISTIC ORCHESTRATION)\n",
    "#### The agent is the main loop that:\n",
    "#### 1. Receives a ProjectSpecification and list of students\n",
    "#### 2. Delegates to tools via an executor\n",
    "#### 3. Follows a rule-based planner for deterministic ordering\n",
    "#### 4. Returns final matching decisions\n",
    "#### ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b512775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_spec_to_row(spec: ProjectSpecification) -> pd.Series:\n",
    "    role_skill_map = {}\n",
    "\n",
    "    for r in spec.roles:\n",
    "        canonical_skills = []\n",
    "\n",
    "        for raw_skill in r.required_skills:\n",
    "            hits = skill_index.search(raw_skill, top_k=3)\n",
    "\n",
    "            # à¹€à¸à¹‡à¸šà¸Šà¸·à¹ˆà¸­ canonical skill\n",
    "            canonical_skills.extend(\n",
    "                h[\"skill_name\"].lower() for h in hits\n",
    "            )\n",
    "\n",
    "        # dedup\n",
    "        role_skill_map[r.role.lower()] = list(set(canonical_skills))\n",
    "\n",
    "    role_quota_map = {\n",
    "        r.role.lower(): r.quota\n",
    "        for r in spec.roles\n",
    "    }\n",
    "\n",
    "    return pd.Series({\n",
    "        \"project_id\": \"P_CHAT\",\n",
    "        \"title\": spec.project_summary[:50],\n",
    "        \"description\": spec.project_summary,\n",
    "        \"role_skill_map\": role_skill_map,     # ðŸ”¥ canonical now\n",
    "        \"role_quota_map\": role_quota_map,\n",
    "        \"min_score\": 0.35\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_legality(proposed: str, allowed: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Ensure proposed action is legal.\n",
    "    Fallback to first allowed action if illegal.\n",
    "    \"\"\"\n",
    "    if proposed in allowed:\n",
    "        return proposed\n",
    "    return allowed[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutonomousMatchingAgent:\n",
    "    def __init__(self, policy, executor):\n",
    "        self.executor = executor\n",
    "        self.policy = policy\n",
    "\n",
    "    def run(self, project_spec, students_df):\n",
    "        project_row = project_spec_to_row(project_spec)\n",
    "\n",
    "        state = AgentState(\n",
    "            project_spec=project_spec,\n",
    "            project_row=project_row,\n",
    "            students_df=students_df\n",
    "        )\n",
    "\n",
    "        max_steps = 10\n",
    "        while not state.done and state.steps < max_steps:\n",
    "            state.steps += 1\n",
    "\n",
    "            view = build_state_view(state)\n",
    "            allowed = legal_actions(view)\n",
    "            proposed = self.policy.choose(view, allowed)\n",
    "            action = enforce_legality(proposed, allowed)\n",
    "\n",
    "            state = self.executor.execute(action, state)\n",
    "\n",
    "            if action == \"PERSIST\":\n",
    "                state.done = True\n",
    "\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e761567",
   "metadata": {},
   "source": [
    "# interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyIntent(dspy.Signature):\n",
    "    user_message = dspy.InputField()\n",
    "    intent = dspy.OutputField(\n",
    "        desc=\"One of: CREATE_PROJECT, RUN_MATCHING, ASK_EXPLANATION, MODIFY_CONSTRAINT, CHAT\"\n",
    "    )\n",
    "\n",
    "class IntentRouter(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.classifier = dspy.Predict(ClassifyIntent)\n",
    "        \n",
    "    def route(self, text: str, state: AgentState) -> str:\n",
    "        text_l = text.lower()\n",
    "\n",
    "        if state.flags.get(\"matched\") and text_l.startswith(\"à¸—à¸³à¹„à¸¡\"):\n",
    "            return \"ASK_EXPLANATION\"\n",
    "\n",
    "        if state.flags.get(\"project_ready\") and any(k in text_l for k in [\"à¸ˆà¸±à¸”à¸—à¸µà¸¡\", \"assign\", \"match\", \"à¹€à¸£à¸´à¹ˆà¸¡\", \"run\"]):\n",
    "            return \"RUN_MATCHING\"\n",
    "\n",
    "        if any(k in text_l for k in [\"à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œ\", \"project\", \"à¸—à¸³à¸£à¸°à¸šà¸š\", \"à¸­à¸¢à¸²à¸à¹„à¸”à¹‰\"]):\n",
    "            return \"CREATE_PROJECT\"\n",
    "\n",
    "        # fallback to LLM\n",
    "        return self.classifier(user_message=text).intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf75f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_student_name(text: str) -> str:\n",
    "    \"\"\"\n",
    "    very simple heuristic:\n",
    "    'à¸—à¸³à¹„à¸¡ à¸ªà¸¡à¸Šà¸²à¸¢ à¹„à¸¡à¹ˆà¸œà¹ˆà¸²à¸™' -> 'à¸ªà¸¡à¸Šà¸²à¸¢'\n",
    "    \"\"\"\n",
    "    text = text.replace(\"à¸—à¸³à¹„à¸¡\", \"\").replace(\"à¹„à¸¡à¹ˆà¸œà¹ˆà¸²à¸™\", \"\")\n",
    "    text = text.replace(\"à¹€à¸žà¸£à¸²à¸°à¸­à¸°à¹„à¸£\", \"\")\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0aee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_student(decision_df_by_role, name):\n",
    "    for role, df in decision_df_by_role.items():\n",
    "        match = df[df[\"student_name\"].str.contains(name, case=False)]\n",
    "        if not match.empty:\n",
    "            return match.iloc[0], role\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4eeeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_student(decision_df_by_role: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    # flatten role -> rows\n",
    "    flat = pd.concat(\n",
    "        df.assign(role=role)\n",
    "        for role, df in decision_df_by_role.items()\n",
    "    )\n",
    "\n",
    "    # priority: ACCEPT > UPSKILL > REJECT\n",
    "    priority = {\"ACCEPT\": 3, \"UPSKILL\": 2, \"REJECT\": 1}\n",
    "\n",
    "    final = (\n",
    "        flat.assign(p=flat[\"decision\"].map(priority))\n",
    "            .sort_values(\"p\", ascending=False)\n",
    "            .groupby(\"student_id\", as_index=False)\n",
    "            .first()\n",
    "    )\n",
    "\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9eb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop(agent: AutonomousMatchingAgent, extractor: ProjectExtractorTool):\n",
    "\n",
    "    state = AgentState(students_df=students_df)\n",
    "    router = IntentRouter()\n",
    "\n",
    "    print(\"ðŸ¤– à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¹ˆà¸§à¸¢à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰ ðŸ˜Š\")\n",
    "\n",
    "    while True:\n",
    "        user_text = input(\"ðŸ‘¤ \")\n",
    "        if user_text.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        intent = router.route(user_text, state)\n",
    "\n",
    "        # --- Free chat (clarification loop) ---\n",
    "        if intent == \"CHAT\":\n",
    "            print(\"ðŸ¤– à¹€à¸¥à¹ˆà¸²à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸„à¸£à¹ˆà¸²à¸§ à¹† à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š à¹€à¸”à¸µà¹‹à¸¢à¸§à¸œà¸¡à¸ˆà¸±à¸”à¸à¸²à¸£à¹ƒà¸«à¹‰\")\n",
    "\n",
    "        # --- User describes project and we extract it ---\n",
    "        elif intent == \"CREATE_PROJECT\":\n",
    "            print(\"ðŸ¤– à¹‚à¸­à¹€à¸„à¸„à¸£à¸±à¸š à¸œà¸¡à¸ªà¸£à¸¸à¸›à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹ƒà¸«à¹‰à¸™à¸°\")\n",
    "            try:\n",
    "                spec = extractor(\n",
    "                    project_description=user_text,\n",
    "                    headcount=3,\n",
    "                    duration=\"3 months\"\n",
    "                )\n",
    "                \n",
    "                state.conversation.extracted_project = spec\n",
    "                state.flags[\"project_ready\"] = True\n",
    "\n",
    "                print(\"ðŸ¤– à¸œà¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸²à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸„à¸·à¸­:\")\n",
    "                print(json.dumps(ProjectSpecification.to_dict(spec), indent=2, ensure_ascii=False))\n",
    "\n",
    "                print(\"ðŸ¤– à¸–à¹‰à¸²à¹‚à¸­à¹€à¸„ à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸² 'à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹€à¸¥à¸¢' à¹„à¸”à¹‰à¸„à¸£à¸±à¸š\")\n",
    "            except Exception as e:\n",
    "                print(f\"ðŸ¤– à¸‚à¸­à¹‚à¸—à¸©à¸™à¸°à¸„à¸£à¸±à¸š à¸œà¸¡à¸ªà¸£à¸¸à¸›à¹„à¸¡à¹ˆà¹„à¸”à¹‰ ({e})\")\n",
    "\n",
    "        # --- Trigger autonomous matching ---\n",
    "        elif intent == \"RUN_MATCHING\":\n",
    "            if not state.conversation.extracted_project:\n",
    "                print(\"ðŸ¤– à¸‚à¸­à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸à¹ˆà¸­à¸™à¸™à¸°à¸„à¸£à¸±à¸š\")\n",
    "                continue\n",
    "\n",
    "            print(\"ðŸ¤– à¸à¸³à¸¥à¸±à¸‡à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¸„à¸£à¸±à¸š â³\")\n",
    "\n",
    "            final_state = agent.run(\n",
    "                project_spec=state.conversation.extracted_project,\n",
    "                students_df=students_df\n",
    "            )\n",
    "\n",
    "            # âœ… à¹€à¸à¹‡à¸š state à¸«à¸¥à¸±à¸‡ run à¹€à¸ªà¸£à¹‡à¸ˆ\n",
    "            state.flags[\"matched\"] = True\n",
    "            state.decision_df = final_state.decision_df\n",
    "            state.project_row = final_state.project_row\n",
    "\n",
    "            final_students = summarize_by_student(state.decision_df)\n",
    "\n",
    "            accepted = (final_students[\"decision\"] == \"ACCEPT\").sum()\n",
    "            rejected = (final_students[\"decision\"] == \"REJECT\").sum()\n",
    "            upskill  = (final_students[\"decision\"] == \"UPSKILL\").sum()\n",
    "\n",
    "\n",
    "            print(\"ðŸ¤– à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š ðŸŽ‰\")\n",
    "            print(f\"âœ“ à¸¢à¸­à¸¡à¸£à¸±à¸š: {accepted}\")\n",
    "            print(f\"âœ“ à¸›à¸à¸´à¹€à¸ªà¸˜: {rejected}\")\n",
    "            print(f\"âœ“ à¸­à¸šà¸£à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: {upskill}\")\n",
    "            print(\"ðŸ¤– à¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸£à¸¹à¹‰à¹€à¸«à¸•à¸¸à¸œà¸¥à¸‚à¸­à¸‡à¹ƒà¸„à¸£ à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸² 'à¸—à¸³à¹„à¸¡ <à¸Šà¸·à¹ˆà¸­>' à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š\")\n",
    "            \n",
    "            \n",
    "        elif intent == \"ASK_EXPLANATION\":\n",
    "            if not state.flags.get(\"matched\"):\n",
    "                print(\"ðŸ¤– à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š\")\n",
    "                continue\n",
    "\n",
    "            name = extract_student_name(user_text)\n",
    "            row, role = find_student(state.decision_df, name)\n",
    "\n",
    "            if row is None:\n",
    "                print(\"ðŸ¤– à¸œà¸¡à¸«à¸²à¸„à¸™à¸™à¸±à¹‰à¸™à¹„à¸¡à¹ˆà¹€à¸ˆà¸­à¸„à¸£à¸±à¸š\")\n",
    "                continue\n",
    "\n",
    "            ctx = DecisionValidatorTool._build_context(\n",
    "                match_row=row,\n",
    "                project_row=state.project_row,\n",
    "                role=role\n",
    "            )\n",
    "\n",
    "            explanation = explainer.explain_decision(ctx)\n",
    "\n",
    "            print(f\"ðŸ¤– à¹€à¸«à¸•à¸¸à¸œà¸¥à¸ªà¸³à¸«à¸£à¸±à¸š {row['student_name']}:\")\n",
    "            print(explanation)\n",
    "\n",
    "        else:\n",
    "            print(\"ðŸ¤– à¸œà¸¡à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆ à¸¥à¸­à¸‡à¸­à¸˜à¸´à¸šà¸²à¸¢à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹€à¸žà¸´à¹ˆà¸¡à¸­à¸µà¸à¸™à¸´à¸”à¹„à¸”à¹‰à¹„à¸«à¸¡à¸„à¸£à¸±à¸š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbcd78",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "67cb8e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Planner, Executor, and Agent initialized.\n"
     ]
    }
   ],
   "source": [
    "executor = ActionExecutor(tool_registry)\n",
    "policy = ActionPolicy()\n",
    "\n",
    "agent = AutonomousMatchingAgent(\n",
    "    policy=policy,\n",
    "    executor=executor\n",
    ")\n",
    "\n",
    "print(\"âœ“ Planner, Executor, and Agent initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cfbe5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¹ˆà¸§à¸¢à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰ ðŸ˜Š\n",
      "ðŸ¤– à¹‚à¸­à¹€à¸„à¸„à¸£à¸±à¸š à¸œà¸¡à¸ªà¸£à¸¸à¸›à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹ƒà¸«à¹‰à¸™à¸°\n",
      "ðŸ¤– à¸œà¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸²à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¸„à¸·à¸­:\n",
      "{\n",
      "  \"project_summary\": \"à¸žà¸±à¸’à¸™à¸²à¹à¸¥à¸°à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ model prediction à¹€à¸žà¸·à¹ˆà¸­à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸à¸²à¸£à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸—à¸²à¸‡à¸˜à¸¸à¸£à¸à¸´à¸ˆà¸«à¸£à¸·à¸­à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µ à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸à¸²à¸£à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸à¸²à¸£à¸à¸¶à¸ model à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š à¹à¸¥à¸°à¸à¸²à¸£ deploy model à¹ƒà¸™à¸£à¸°à¸šà¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸•\",\n",
      "  \"project_type\": [\n",
      "    \"Machine Learning\",\n",
      "    \"Data Science\",\n",
      "    \"Software Development\"\n",
      "  ],\n",
      "  \"headcount\": 3,\n",
      "  \"duration_months\": 3,\n",
      "  \"roles\": [\n",
      "    {\n",
      "      \"role\": \"DATA SCIENTIST\",\n",
      "      \"quota\": 1,\n",
      "      \"responsibility\": \"à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¹à¸¥à¸°à¸à¸²à¸£à¸à¸¶à¸ model prediction\",\n",
      "      \"required_skills\": [\n",
      "        \"Python (Pandas, Scikit-learn, TensorFlow/PyTorch)\",\n",
      "        \"à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸ªà¸–à¸´à¸•à¸´\",\n",
      "        \"à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (ETL)\",\n",
      "        \"à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¸à¹ˆ (Big Data) - à¹€à¸•à¸£à¸µà¸¢à¸¡à¸ªà¸³à¸«à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‚à¸™à¸²à¸”à¹ƒà¸«à¸à¹ˆ\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"MACHINE LEARNING ENGINEER\",\n",
      "      \"quota\": 1,\n",
      "      \"responsibility\": \"à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¹à¸¥à¸°à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡ model prediction à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š model à¹à¸¥à¸°à¸à¸²à¸£ optimize performance\",\n",
      "      \"required_skills\": [\n",
      "        \"Python (TensorFlow, PyTorch, Scikit-learn)\",\n",
      "        \"à¸à¸²à¸£à¸à¸¶à¸ model à¹à¸¥à¸°à¸à¸²à¸£ optimize\",\n",
      "        \"à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£ cloud (AWS/GCP/Azure)\",\n",
      "        \"à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¹à¸¥à¸°à¸à¸²à¸£ deploy model\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"DEVOPS/SRE ENGINEER\",\n",
      "      \"quota\": 1,\n",
      "      \"responsibility\": \"à¸à¸²à¸£ deploy model à¹ƒà¸™à¸£à¸°à¸šà¸šà¸à¸²à¸£à¸œà¸¥à¸´à¸• à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£ infrastructure à¹à¸¥à¸°à¸à¸²à¸£ monitor system\",\n",
      "      \"required_skills\": [\n",
      "        \"à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£ cloud (AWS/GCP/Azure)\",\n",
      "        \"Docker à¹à¸¥à¸° Kubernetes\",\n",
      "        \"CI/CD Pipeline\",\n",
      "        \"à¸à¸²à¸£ monitor à¹à¸¥à¸° log management\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"assumptions\": [\n",
      "    \"à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸à¸¶à¸ model prediction\",\n",
      "    \"à¸¡à¸µà¸£à¸°à¸šà¸š cloud à¸—à¸µà¹ˆà¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£ deploy model\",\n",
      "    \"à¸—à¸µà¸¡à¸¡à¸µà¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸žà¸·à¹‰à¸™à¸à¸²à¸™à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š machine learning à¹à¸¥à¸°à¸à¸²à¸£à¸žà¸±à¸’à¸™à¸²à¸‹à¸­à¸Ÿà¸•à¹Œà¹à¸§à¸£à¹Œ\"\n",
      "  ],\n",
      "  \"risks\": [\n",
      "    \"à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸¸à¸“à¸ à¸²à¸žà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸­à¸²à¸ˆà¸—à¸³à¹ƒà¸«à¹‰ model prediction à¹„à¸¡à¹ˆà¸¡à¸µà¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸ž\",\n",
      "    \"à¸à¸²à¸£ deploy model à¸­à¸²à¸ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸²à¹ƒà¸™à¸à¸²à¸£ integrate à¸à¸±à¸šà¸£à¸°à¸šà¸šà¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ\",\n",
      "    \"à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸£à¸·à¸­ requirement à¸­à¸²à¸ˆà¸—à¸³à¹ƒà¸«à¹‰à¸•à¹‰à¸­à¸‡à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡ model à¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡\"\n",
      "  ]\n",
      "}\n",
      "ðŸ¤– à¸–à¹‰à¸²à¹‚à¸­à¹€à¸„ à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸² 'à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹€à¸¥à¸¢' à¹„à¸”à¹‰à¸„à¸£à¸±à¸š\n",
      "ðŸ¤– à¸à¸³à¸¥à¸±à¸‡à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¸„à¸£à¸±à¸š â³\n",
      "ðŸ¤– à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š ðŸŽ‰\n",
      "âœ“ à¸¢à¸­à¸¡à¸£à¸±à¸š: 2\n",
      "âœ“ à¸›à¸à¸´à¹€à¸ªà¸˜: 0\n",
      "âœ“ à¸­à¸šà¸£à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: 0\n",
      "ðŸ¤– à¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸£à¸¹à¹‰à¹€à¸«à¸•à¸¸à¸œà¸¥à¸‚à¸­à¸‡à¹ƒà¸„à¸£ à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸² 'à¸—à¸³à¹„à¸¡ <à¸Šà¸·à¹ˆà¸­>' à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š\n",
      "ðŸ¤– à¸à¸³à¸¥à¸±à¸‡à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¸„à¸£à¸±à¸š â³\n",
      "ðŸ¤– à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š ðŸŽ‰\n",
      "âœ“ à¸¢à¸­à¸¡à¸£à¸±à¸š: 2\n",
      "âœ“ à¸›à¸à¸´à¹€à¸ªà¸˜: 0\n",
      "âœ“ à¸­à¸šà¸£à¸¡à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: 0\n",
      "ðŸ¤– à¸–à¹‰à¸²à¸­à¸¢à¸²à¸à¸£à¸¹à¹‰à¹€à¸«à¸•à¸¸à¸œà¸¥à¸‚à¸­à¸‡à¹ƒà¸„à¸£ à¸žà¸´à¸¡à¸žà¹Œà¸§à¹ˆà¸² 'à¸—à¸³à¹„à¸¡ <à¸Šà¸·à¹ˆà¸­>' à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m extractor = ProjectExtractorTool()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mchat_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mchat_loop\u001b[39m\u001b[34m(agent, extractor)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ¤– à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š à¸œà¸¡à¸Šà¹ˆà¸§à¸¢à¸ˆà¸±à¸”à¸—à¸µà¸¡à¹ƒà¸«à¹‰à¹‚à¸›à¸£à¹€à¸ˆà¸à¸•à¹Œà¹„à¸”à¹‰ ðŸ˜Š\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     user_text = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mðŸ‘¤ \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m user_text.lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/living_lab/living_lab/lib/python3.12/site-packages/ipykernel/kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/living_lab/living_lab/lib/python3.12/site-packages/ipykernel/kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "extractor = ProjectExtractorTool()\n",
    "chat_loop(agent, extractor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "living_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
